{
  "hash": "24a4e78a86b35bcf4aba4c9729a25b52",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Possion regression\"\nformat:\n  html:\n    toc: true\n    html-math-method: katex\n    css: style.css  \n    theme:\n      light: cosmo\n      dark: [cosmo, theme-dark.scss]\nexecute: \n   echo: false\neditor_options: \n  chunk_output_type: console\n---\n\n```{=html}\n<style>\n.table-hover > tbody > tr:hover { \n  background-color: #f4f442;\n}\n</style>\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReading\n- Ch 4.1,4.2.1 - 4.2.3,5.2\n- Skim sections 5.1, 5.2.3,5.3,.5.4\n  \n# Generalized linear models (GLM)\n\n- GLMs have three different parts (see page 121:\n  \n  1. Random Component:\n      - $Y$, for logistic regression, $Y$ has a Bernoulli distribution\n  \n  2. Systematic Component:\n      - This specifies a linear combination of the regression parameters with `features`, and this part is referred to as the `linear predictor`\n      - $\\beta_0 + \\beta_1x_1 + .... + \\beta_px_p$\n      \n  3. LINK FUNCTION:\n      - Specifies how the expected value of the `random component` $E[Y]$ is linked to the `sysmatic` component.\n      - $\\text{logit}(\\pi) = \\beta_0 + \\beta_1x_1 + .... + \\beta_px_p$\n      - where $E[Y] = \\pi$\n\n\n## Class Announcements\n\nNo HW this week\n\nLab-1 due in 1 week\n\n## Roadmap\n\n**Rearview Mirror**\n\n- Model unordered and ordered categorical response \n\n**Today**\n\n- Poisson probability model\n\n- Poisson regression model, estimation, and statistical inference\n\n- Model Comparison Criteria, Model Assessment, Goodness of Fit\n\n**Looking Ahead**\n\n- Univariate and multivariate time-series\n\n- Notion of dependency and stationarity\n\n# Poisson Distribution \n\nRecall that the Poisson distribution models count data i.e. the number of events between 0,1,... for a random variable $X$. The distribution is:\n\n$$P(X=k)=\\frac{\\lambda^ke^{-\\lambda}}{k!}$$\nOne key assumption of the distribution is that $E(X)=Var(X)=\\lambda$, meaning that the mean and variance of the distribution is the same.\n\nAs we will see this is a limiting assumption when we do Poisson Regression.\n\n\nIn Poisson regression we model the log of $\\lambda$ (the mean assuming a Poisson distribution) as a linear combination of the features:\n\n$$\\text{log}(\\lambda_i)=\\text{log}(E(Y_i|X_i))=X_i\\beta$$\n\nWe use maximum likelihood to estimate the coefficients in $\\beta$ assuming that $Y$ follows an iid Poisson distribution:\n\n$$max_\\beta\\ L(\\beta|Y_1,...,Y_n)=P(Y_1=y_1,...,Y_n=y_n|\\beta)=\\Pi_i\\frac{e^{y_iX_i\\beta}e^{-e^{X_i\\beta}}}{y_i!}$$\n\nThe log likelihood has no closed form solution, so we estimate the parameters beta using numerical methods just like in logistic regression.\n\nFor each $y_i$ we can calculate and predict fitted values using the MLE of the coefficients:\n\n$$\\hat{y_i}=E(y_i|X_i)=\\lambda_i=e^{X_i\\beta}$$\nUnder Poisson regression, the $Var(\\hat{y_i})=\\lambda_i=e^{X_i\\beta}$ so that Poisson regression naturally has heteroskedasticity in the results.\n\nBecause coefficients are linear on the log scale, when exponentiated they multiply the expected mean outcome. This is similar to the interpretation in logistic regression except we are not dealing with odds ratios but rather changes in the average outcome.\n\n## Parameter\n\nEqual Mean and Variance and Overdispersion\n\nThis assumption of equal mean and variance is often not met when actually fitting to data, which results in what is known as overdispersion where the variance in the data is larger than the variance fit in the model.\n\nThis usually can be remedied by adding more $X$ variables into the model to improve the fit.\n\nAnother option is to fit what are known as a quasi poisson model or negative binomial regression model. In both cases, we relax the equal mean and variance assumption by adding an additional parameter to the variance of the response variable, allowing it to be larger than the mean.\n\nIn quasi poisson regression we set $\n\n$$\\text{V}[\\hat{y_i}]=\\theta\\lambda_i$$ \nand in negative binomial regression we set \n\n$$\\text{V}[\\hat{y_i}]=\\lambda_i+\\kappa\\lambda_i^2$$\n\n\n# Case Study: Modeling the Number of Awards \n\n## Target\n\n  - `The number of awards` earned by students based on the `type of programs students were enrolled` in using historical admission data. \n  - `num_awards`: the number of awards earned by students at a high school in a year\n  - `math`: students’ scores on their final math exam\n  - `prog`: the type of program in which the students were enrolled \n    - `1 = General`\n    - `2 = Academic` \n    - `3 = Vocational`\n\n## EDA\n\n- What is the number of observations?\n- What is the number of variables? \n- Are there any redundant variables?\n- Are there any missing information?\n- Are there any duplicated records?\n- Are there any values in each of the variables that seem unreasonable?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Modeling the Number of Awards</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> X </th>\n   <th style=\"text-align:right;\"> id </th>\n   <th style=\"text-align:right;\"> num_awards </th>\n   <th style=\"text-align:left;\"> prog </th>\n   <th style=\"text-align:right;\"> math </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 45 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> Vocational </td>\n   <td style=\"text-align:right;\"> 41 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 108 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> General </td>\n   <td style=\"text-align:right;\"> 41 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> Vocational </td>\n   <td style=\"text-align:right;\"> 44 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 67 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> Vocational </td>\n   <td style=\"text-align:right;\"> 42 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 153 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> Vocational </td>\n   <td style=\"text-align:right;\"> 40 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 51 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> General </td>\n   <td style=\"text-align:right;\"> 42 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         X         id num_awards       prog       math \n         0          0          0          0          0 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\newpage\n\n### Univariate Analysis\n\n- Use a frequency table and a bar plot to explore the distribution of the response variable(num_awards). What do you learn?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Modeling the Number of Awards</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> Number of awards </th>\n   <th style=\"text-align:right;\"> N </th>\n   <th style=\"text-align:right;\"> Proportion </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 124 </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 49 </td>\n   <td style=\"text-align:right;\"> 0.24 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The dot-dot notation (`..prop..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(prop)` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](wk5_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- The prog is the committee’s key explanatory variable of interest. It has three levels: academic, general, and vocational. Use a frequency table and a bar plot to examine its distribution. What do you discover? \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Modeling the Number of Awards</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  Type of program </th>\n   <th style=\"text-align:right;\"> N </th>\n   <th style=\"text-align:right;\"> Proportion </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Academic </td>\n   <td style=\"text-align:right;\"> 105 </td>\n   <td style=\"text-align:right;\"> 0.52 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> General </td>\n   <td style=\"text-align:right;\"> 45 </td>\n   <td style=\"text-align:right;\"> 0.22 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Vocational </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 0.25 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n::: {.cell-output-display}\n![](wk5_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- Plot the distribution of math scores. What are the range and average math scores?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](wk5_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n### Bivariate Analysis\n\n- Examine the associations between the number of awards and program and math scores.\n\n- The graph below shows the distribution of the number of awards by program types. How are awards distributed among different programs?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](wk5_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- The graph below shows the distribution of the number of awards and students' math scores. Is there any clear relationship between them?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](wk5_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- Use summary_factorlist() function from the finalfit package to tabulate data. What do you learn from the EDA?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Modeling the Number of Awards</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Dependent: num_awards </th>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\"> unit </th>\n   <th style=\"text-align:left;\"> value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> prog </td>\n   <td style=\"text-align:left;\"> Academic </td>\n   <td style=\"text-align:left;\"> Mean (sd) </td>\n   <td style=\"text-align:left;\"> 1.0 (1.3) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> General </td>\n   <td style=\"text-align:left;\"> Mean (sd) </td>\n   <td style=\"text-align:left;\"> 0.2 (0.4) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> Vocational </td>\n   <td style=\"text-align:left;\"> Mean (sd) </td>\n   <td style=\"text-align:left;\"> 0.2 (0.5) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> math </td>\n   <td style=\"text-align:left;\"> [33.0,75.0] </td>\n   <td style=\"text-align:left;\"> Mean (sd) </td>\n   <td style=\"text-align:left;\"> 0.6 (1.1) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Model Development\n\n- Given the specification of a poisson regression model below,\n\n$$\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 prog + \\beta_2 math + u$$\n\n- Estimate and interpret the model results using `glm()` and the correct `family` parameter:\n\n## Coefficients\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoisson.mod.1 <- poisson.mod.1 <- glm(num_awards ~ prog + math, \n                                      data = df, \n                                      family = poisson)\n\nsummary(poisson.mod.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = num_awards ~ prog + math, family = poisson, data = df)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.2043  -0.8436  -0.5106   0.2558   2.6796  \n\nCoefficients:\n               Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    -4.16327    0.66288  -6.281 3.37e-10 ***\nprogGeneral    -1.08386    0.35825  -3.025  0.00248 ** \nprogVocational -0.71405    0.32001  -2.231  0.02566 *  \nmath            0.07015    0.01060   6.619 3.63e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 287.67  on 199  degrees of freedom\nResidual deviance: 189.45  on 196  degrees of freedom\nAIC: 373.5\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- The `negative coefficients` of the `general` and `vocational programs` indicate that the number of wards is lower in these two programs.\n\n- The positive coefficients of `math` score indicates that the number of awards is increasing as the math score increases.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(exp(coef(poisson.mod.1)) - 1) * 100\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept)    progGeneral progVocational           math \n    -98.444332     -66.171250     -51.034289       7.267164 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo have a more convenient way to interpret these coefficients, we compute and use percentage changes\n  - Holding `program type constant`, 1 unit increase in math score increase the mean number of awards by 7%.\n\n  - Hold `math score constant`; \n    - a student in the `general program`, on average, receives 66% fewer awards than students in the `academic program`\n    - a student in the `vocational program`, on average, receives 51% fewer awards than students in the academic program\n\n### Anova()\n\n- Test the overall effect of prog using `Anova()`:   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: num_awards\n     LR Chisq Df Pr(>Chisq)    \nprog   14.572  2  0.0006852 ***\nmath   45.010  1   1.96e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- Based on the p-values, the prog, taken together, is a statistically significant predictor of the number of awards.\n\n\n## Plot the result \n\n- Plot the fitted values across the three programs and discuss how the number of awards is associated with math scores.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-63d1b29616fbbb3443bc\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-63d1b29616fbbb3443bc\">{\"x\":{\"data\":[{\"x\":[37.987474045343696,44.859727220609784,43.111932593397796,49.374927813746034,46.121007514558734,40.905098632350565,43.210339999198915,49.079721821099518,41.952066815458238,41.1439368294552,50.272659737430516,44.176397106423977,51.679357206635174,47.864228901267055,45.380091855116191,50.093402485921978,43.159385615959764,53.808729588240382,45.35456855278462,43.071672349981966,49.000898814760149,53.241255488432941,49.612552575208248,47.671335774660108,51.099708103947343,45.02680605240166,53.9444376418367,50.776847481168808,52.641788030602036,50.21194160860032,56.970343842916193,51.044108440726994,48.69767170660198,48.266087065823378,51.686628797650336,52.701469909213486,59.144146895222363,66.087517949938771,57.122267756238578,54.230348882079127,54.145282811485231,54.201314322277902,54.375905033759771,49.257039132155477,57.973874672874807,60.060647225193676,51.37026614956558,62.708838957734407,50.094131860695782,52.893290662765502,52.668880225531758,54.703090535290542,55.790259686671199,48.840866207703947,60.804918393120168,56.74555317647755,66.088003834337002,59.809783002547917,57.045356717705729,58.74409795869142,57.958674974925813,56.641014461778106,64.223477824218577,60.94984481558204,54.716842072084546,56.947841531410816,62.306059526652099,55.964362544193861,50.804841607436536,62.895295135863122,61.324235962703824,66.747195655666289,48.352145859971642,61.337715625017879,65.05604361016303,62.193685843981804,60.8541169770062,64.296759176626807,65.204247866384691,57.384544486552478,72.216150492429733,61.681176474317908,58.241115174070003,62.919417667388913,63.61817939225584,72.370055724494165,63.662134632468224,68.871974620036781,70.205181806348264,65.692045576497918,62.119313941709699,67.353811175189918,64.154249105416241,62.884870303794742,67.781548815406865,75.266471932828424,69.134361540712419,65.157446009851995,71.024147589877245,71.009535162523392,59.972741095721723,70.667856793478137,70.756046914123004,71.864468254707759,73.356720425933602],\"y\":[-0.010723130684345966,0.19247320257127287,-0.17025319505482914,0.0089780642651021425,0.063113355822861206,1.1289139891043305,0.87539370823651552,0.03488168166950345,0.19495653649792077,-0.079225308168679481,-0.036993942037224781,0.0023807796649634727,-0.12651725681498649,0.92893101852387194,-0.078723906818777334,2.8370115577243267,-0.11434956416487695,1.1055098002776504,0.93880713311955333,-0.056053508631885046,-0.047006231360137457,0.80980339972302318,1.9047163380309939,-0.049612275697290903,0.1805521876551211,0.10282864151522519,-0.099838246591389179,0.99905315767973657,-0.038838219922035927,-0.10885734353214503,1.1885205382481216,0.149807117972523,0.069259757455438387,0.1354606273584068,-0.017621092312037956,1.1579329903237521,1.0375779164023697,2.1389007174409924,-0.081552113685756933,0.89705936554819343,1.0065863980911671,0.038235388882458199,0.19579062163829802,2.1539298332296313,3.1472823700867592,1.0748730684630572,0.080027831532061111,0.18988493541255597,0.9124412981793284,0.88541266648098826,-0.045911134593188768,-0.10396031523123384,0.88083319244906311,-0.1088476799428463,1.122949052322656,-0.087157360278069973,0.025736569147557009,3.0955669634044169,1.1718361751176416,-0.19899094365537168,-0.1629224767908454,0.015530741307884455,2.9494484131224454,0.96659046206623311,0.19125617416575552,2.9712858898565173,-0.084457209520041945,0.076867460273206234,-0.0016892698593437561,1.1069028443656861,4.8305334413424132,0.043161099683493381,-0.12090527256950737,0.889194932859391,1.8160090745426714,4.0967643583193425,0.9953371174633503,1.1025326177477837,2.8387086998671291,2.9398713514208792,2.0864390558563173,0.13437942061573266,1.1864427242428064,1.0817241836339235,2.9975033924914896,1.9943003025837243,0.098886876273900248,5.9998813059180973,4.1669501084834337,1.0222775137983262,1.8333738940767943,1.95923565113917,1.0057101609185337,1.8816494526341558,0.89058530470356345,0.9785453706979752,0.033830508589744568,0.90744035253301258,1.8502438045106828,4.8223569300025702,1.1706669799983502,2.1557007604278624,1.051454698573798,0.15609541637822988,2.9041480598039926],\"text\":[\"math: 38<br />num_awards: 0<br />prog: Academic\",\"math: 45<br />num_awards: 0<br />prog: Academic\",\"math: 43<br />num_awards: 0<br />prog: Academic\",\"math: 49<br />num_awards: 0<br />prog: Academic\",\"math: 46<br />num_awards: 0<br />prog: Academic\",\"math: 41<br />num_awards: 1<br />prog: Academic\",\"math: 43<br />num_awards: 1<br />prog: Academic\",\"math: 49<br />num_awards: 0<br />prog: Academic\",\"math: 42<br />num_awards: 0<br />prog: Academic\",\"math: 41<br />num_awards: 0<br />prog: Academic\",\"math: 50<br />num_awards: 0<br />prog: Academic\",\"math: 44<br />num_awards: 0<br />prog: Academic\",\"math: 52<br />num_awards: 0<br />prog: Academic\",\"math: 48<br />num_awards: 1<br />prog: Academic\",\"math: 45<br />num_awards: 0<br />prog: Academic\",\"math: 50<br />num_awards: 3<br />prog: Academic\",\"math: 43<br />num_awards: 0<br />prog: Academic\",\"math: 54<br />num_awards: 1<br />prog: Academic\",\"math: 45<br />num_awards: 1<br />prog: Academic\",\"math: 43<br />num_awards: 0<br />prog: Academic\",\"math: 49<br />num_awards: 0<br />prog: Academic\",\"math: 53<br />num_awards: 1<br />prog: Academic\",\"math: 50<br />num_awards: 2<br />prog: Academic\",\"math: 48<br />num_awards: 0<br />prog: Academic\",\"math: 51<br />num_awards: 0<br />prog: Academic\",\"math: 45<br />num_awards: 0<br />prog: Academic\",\"math: 54<br />num_awards: 0<br />prog: Academic\",\"math: 51<br />num_awards: 1<br />prog: Academic\",\"math: 53<br />num_awards: 0<br />prog: Academic\",\"math: 50<br />num_awards: 0<br />prog: Academic\",\"math: 57<br />num_awards: 1<br />prog: Academic\",\"math: 51<br />num_awards: 0<br />prog: Academic\",\"math: 49<br />num_awards: 0<br />prog: Academic\",\"math: 48<br />num_awards: 0<br />prog: Academic\",\"math: 52<br />num_awards: 0<br />prog: Academic\",\"math: 53<br />num_awards: 1<br />prog: Academic\",\"math: 59<br />num_awards: 1<br />prog: Academic\",\"math: 66<br />num_awards: 2<br />prog: Academic\",\"math: 57<br />num_awards: 0<br />prog: Academic\",\"math: 54<br />num_awards: 1<br />prog: Academic\",\"math: 54<br />num_awards: 1<br />prog: Academic\",\"math: 54<br />num_awards: 0<br />prog: Academic\",\"math: 54<br />num_awards: 0<br />prog: Academic\",\"math: 49<br />num_awards: 2<br />prog: Academic\",\"math: 58<br />num_awards: 3<br />prog: Academic\",\"math: 60<br />num_awards: 1<br />prog: Academic\",\"math: 51<br />num_awards: 0<br />prog: Academic\",\"math: 63<br />num_awards: 0<br />prog: Academic\",\"math: 50<br />num_awards: 1<br />prog: Academic\",\"math: 53<br />num_awards: 1<br />prog: Academic\",\"math: 53<br />num_awards: 0<br />prog: Academic\",\"math: 55<br />num_awards: 0<br />prog: Academic\",\"math: 56<br />num_awards: 1<br />prog: Academic\",\"math: 49<br />num_awards: 0<br />prog: Academic\",\"math: 61<br />num_awards: 1<br />prog: Academic\",\"math: 57<br />num_awards: 0<br />prog: Academic\",\"math: 66<br />num_awards: 0<br />prog: Academic\",\"math: 60<br />num_awards: 3<br />prog: Academic\",\"math: 57<br />num_awards: 1<br />prog: Academic\",\"math: 59<br />num_awards: 0<br />prog: Academic\",\"math: 58<br />num_awards: 0<br />prog: Academic\",\"math: 57<br />num_awards: 0<br />prog: Academic\",\"math: 64<br />num_awards: 3<br />prog: Academic\",\"math: 61<br />num_awards: 1<br />prog: Academic\",\"math: 55<br />num_awards: 0<br />prog: Academic\",\"math: 57<br />num_awards: 3<br />prog: Academic\",\"math: 62<br />num_awards: 0<br />prog: Academic\",\"math: 56<br />num_awards: 0<br />prog: Academic\",\"math: 51<br />num_awards: 0<br />prog: Academic\",\"math: 63<br />num_awards: 1<br />prog: Academic\",\"math: 61<br />num_awards: 5<br />prog: Academic\",\"math: 67<br />num_awards: 0<br />prog: Academic\",\"math: 48<br />num_awards: 0<br />prog: Academic\",\"math: 61<br />num_awards: 1<br />prog: Academic\",\"math: 65<br />num_awards: 2<br />prog: Academic\",\"math: 62<br />num_awards: 4<br />prog: Academic\",\"math: 61<br />num_awards: 1<br />prog: Academic\",\"math: 64<br />num_awards: 1<br />prog: Academic\",\"math: 65<br />num_awards: 3<br />prog: Academic\",\"math: 57<br />num_awards: 3<br />prog: Academic\",\"math: 72<br />num_awards: 2<br />prog: Academic\",\"math: 62<br />num_awards: 0<br />prog: Academic\",\"math: 58<br />num_awards: 1<br />prog: Academic\",\"math: 63<br />num_awards: 1<br />prog: Academic\",\"math: 64<br />num_awards: 3<br />prog: Academic\",\"math: 72<br />num_awards: 2<br />prog: Academic\",\"math: 64<br />num_awards: 0<br />prog: Academic\",\"math: 69<br />num_awards: 6<br />prog: Academic\",\"math: 70<br />num_awards: 4<br />prog: Academic\",\"math: 66<br />num_awards: 1<br />prog: Academic\",\"math: 62<br />num_awards: 2<br />prog: Academic\",\"math: 67<br />num_awards: 2<br />prog: Academic\",\"math: 64<br />num_awards: 1<br />prog: Academic\",\"math: 63<br />num_awards: 2<br />prog: Academic\",\"math: 68<br />num_awards: 1<br />prog: Academic\",\"math: 75<br />num_awards: 1<br />prog: Academic\",\"math: 69<br />num_awards: 0<br />prog: Academic\",\"math: 65<br />num_awards: 1<br />prog: Academic\",\"math: 71<br />num_awards: 2<br />prog: Academic\",\"math: 71<br />num_awards: 5<br />prog: Academic\",\"math: 60<br />num_awards: 1<br />prog: Academic\",\"math: 71<br />num_awards: 2<br />prog: Academic\",\"math: 71<br />num_awards: 1<br />prog: Academic\",\"math: 72<br />num_awards: 0<br />prog: Academic\",\"math: 73<br />num_awards: 3<br />prog: Academic\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(248,118,109,1)\",\"opacity\":0.5,\"size\":5.6692913385826778,\"symbol\":\"circle\",\"line\":{\"width\":1.8897637795275593,\"color\":\"rgba(248,118,109,1)\"}},\"hoveron\":\"points\",\"name\":\"Academic\",\"legendgroup\":\"Academic\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[40.84279443975538,42.321552055142817,38.663500275090335,43.166517589055005,41.787458435446027,44.363739411532876,46.185110029764473,42.072455511428416,43.05765020288527,57.230396907404064,38.978887888975443,45.72259746156633,42.755930127575994,42.127085068449375,53.705174659937619,44.979153715446593,53.776477763801815,41.283483712933958,46.303939571045341,46.217029579915106,61.247685962356627,49.214080238528553,48.759231944940986,56.932730667665602,42.195523274131119,54.830565054714683,51.748946764692661,57.216409876756373,35.361970167420807,50.093785469979046,54.734728081896904,49.236366133950654,56.317771462351082,60.388079116679727,54.367635201476517,57.616519567370418,56.006891550309959,59.780924236401916,60.622280243784189,57.18307404834777,47.709186142124238,57.880316935479641,56.22439863309264,63.314328845404091,57.856632206588984],\"y\":[-0.15166963152587415,0.150003063865006,0.09841976538300512,-0.099973635282367468,0.073305166605860006,1.0555959722027182,0.91694955741986628,-0.15822442844510079,-0.052790805883705633,-0.075999225117266186,-0.10517063904553653,-0.012580271624028694,-0.17931181602180005,0.97493087043985727,0.030014454573392857,0.050599289126694202,0.16965492106974128,-0.098140285909175881,-0.096292899735271942,-0.1208865654654801,-0.10383733315393329,-0.11325545432046057,1.0860513775609433,0.17597501808777455,0.090364321321248997,0.10830078376457097,0.014910753723233944,-0.10158804738894106,0.16836796533316373,0.033944143727421772,1.0445161868818105,-0.0084770770743489154,-0.082748938445001849,-0.099754748493433007,-0.016298631951212894,0.80748182665556667,0.13044784190133213,0.17245099395513536,0.073685903381556284,-0.17710734270513059,0.18795666648074988,1.1069569988176227,1.1977336130104959,1.1813850050792098,0.11055792132392528],\"text\":[\"math: 41<br />num_awards: 0<br />prog: General\",\"math: 42<br />num_awards: 0<br />prog: General\",\"math: 39<br />num_awards: 0<br />prog: General\",\"math: 43<br />num_awards: 0<br />prog: General\",\"math: 42<br />num_awards: 0<br />prog: General\",\"math: 44<br />num_awards: 1<br />prog: General\",\"math: 46<br />num_awards: 1<br />prog: General\",\"math: 42<br />num_awards: 0<br />prog: General\",\"math: 43<br />num_awards: 0<br />prog: General\",\"math: 57<br />num_awards: 0<br />prog: General\",\"math: 39<br />num_awards: 0<br />prog: General\",\"math: 46<br />num_awards: 0<br />prog: General\",\"math: 43<br />num_awards: 0<br />prog: General\",\"math: 42<br />num_awards: 1<br />prog: General\",\"math: 54<br />num_awards: 0<br />prog: General\",\"math: 45<br />num_awards: 0<br />prog: General\",\"math: 54<br />num_awards: 0<br />prog: General\",\"math: 41<br />num_awards: 0<br />prog: General\",\"math: 46<br />num_awards: 0<br />prog: General\",\"math: 46<br />num_awards: 0<br />prog: General\",\"math: 61<br />num_awards: 0<br />prog: General\",\"math: 49<br />num_awards: 0<br />prog: General\",\"math: 49<br />num_awards: 1<br />prog: General\",\"math: 57<br />num_awards: 0<br />prog: General\",\"math: 42<br />num_awards: 0<br />prog: General\",\"math: 55<br />num_awards: 0<br />prog: General\",\"math: 52<br />num_awards: 0<br />prog: General\",\"math: 57<br />num_awards: 0<br />prog: General\",\"math: 35<br />num_awards: 0<br />prog: General\",\"math: 50<br />num_awards: 0<br />prog: General\",\"math: 55<br />num_awards: 1<br />prog: General\",\"math: 49<br />num_awards: 0<br />prog: General\",\"math: 56<br />num_awards: 0<br />prog: General\",\"math: 60<br />num_awards: 0<br />prog: General\",\"math: 54<br />num_awards: 0<br />prog: General\",\"math: 58<br />num_awards: 1<br />prog: General\",\"math: 56<br />num_awards: 0<br />prog: General\",\"math: 60<br />num_awards: 0<br />prog: General\",\"math: 61<br />num_awards: 0<br />prog: General\",\"math: 57<br />num_awards: 0<br />prog: General\",\"math: 48<br />num_awards: 0<br />prog: General\",\"math: 58<br />num_awards: 1<br />prog: General\",\"math: 56<br />num_awards: 1<br />prog: General\",\"math: 63<br />num_awards: 1<br />prog: General\",\"math: 58<br />num_awards: 0<br />prog: General\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,186,56,1)\",\"opacity\":0.5,\"size\":5.6692913385826778,\"symbol\":\"circle\",\"line\":{\"width\":1.8897637795275593,\"color\":\"rgba(0,186,56,1)\"}},\"hoveron\":\"points\",\"name\":\"General\",\"legendgroup\":\"General\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[40.806756735593083,43.844488357566298,42.036264678277078,39.638404664583504,45.978750542365013,39.79222036078572,33.145005542971191,46.138862660713492,40.118504464440051,43.748129054903984,37.153079491108656,39.711954902485012,37.705323683470489,39.225651173852384,45.202283137291673,40.069630309380592,39.971362281776962,46.721840506233278,40.146064267680046,39.346248170547184,49.22332310434431,39.169247230328622,40.91960341967642,39.297216347232464,51.836283096484841,40.343193561770022,45.213200917281213,46.849948327802124,40.171846176311377,51.793061287142336,52.168390919454396,50.838403837941584,55.221580462343994,54.351985998079179,56.380332863330842,45.65161576606333,45.253860984556376,47.042921785637738,41.391960207931696,53.106727863103153,50.926146700792017,40.154266389459373,50.374514461494982,57.380221831239759,57.252281351946294,50.681728842109443,56.071308286860585,53.197383312880994,66.177582016028467,74.951890789531177],\"y\":[-0.038471192680299277,0.082347041554749034,-0.021973276976495981,0.16844299202784896,0.16619447469711307,0.14472742481157186,-0.11145441588014365,-0.083047797624021771,0.17389792148023847,-0.075425058417022239,0.027098440192639822,-0.062440706510096783,-0.096925053372979172,0.074002376291900873,0.0302436170168221,0.031493936013430368,0.18641311591491105,0.093149441760033369,1.0767438150011004,0.90894255219027398,0.073480735067278147,-0.14296487141400577,1.0392391108907759,0.11655176840722564,-0.030245246645063173,0.17286221496760845,-0.022807390335947281,0.096488763485103823,0.93354118056595325,0.034901662636548286,1.0471798148006202,0.92576831886544819,-0.0042931471951305755,-0.018867959920316923,0.11835743226110934,0.1090442193672061,-0.052540528215467924,-0.047862448263913393,0.1728359840810299,-0.0051504421047866289,1.109090728778392,-0.060362249612808228,0.097272866871207952,-0.097350757662206897,-0.084414882492274051,1.1285783968865872,1.9908245950005949,-0.017110348958522092,0.13047279762104153,2.1624765034765003],\"text\":[\"math: 41<br />num_awards: 0<br />prog: Vocational\",\"math: 44<br />num_awards: 0<br />prog: Vocational\",\"math: 42<br />num_awards: 0<br />prog: Vocational\",\"math: 40<br />num_awards: 0<br />prog: Vocational\",\"math: 46<br />num_awards: 0<br />prog: Vocational\",\"math: 40<br />num_awards: 0<br />prog: Vocational\",\"math: 33<br />num_awards: 0<br />prog: Vocational\",\"math: 46<br />num_awards: 0<br />prog: Vocational\",\"math: 40<br />num_awards: 0<br />prog: Vocational\",\"math: 44<br />num_awards: 0<br />prog: Vocational\",\"math: 37<br />num_awards: 0<br />prog: Vocational\",\"math: 40<br />num_awards: 0<br />prog: Vocational\",\"math: 38<br />num_awards: 0<br />prog: Vocational\",\"math: 39<br />num_awards: 0<br />prog: Vocational\",\"math: 45<br />num_awards: 0<br />prog: Vocational\",\"math: 40<br />num_awards: 0<br />prog: Vocational\",\"math: 40<br />num_awards: 0<br />prog: Vocational\",\"math: 47<br />num_awards: 0<br />prog: Vocational\",\"math: 40<br />num_awards: 1<br />prog: Vocational\",\"math: 39<br />num_awards: 1<br />prog: Vocational\",\"math: 49<br />num_awards: 0<br />prog: Vocational\",\"math: 39<br />num_awards: 0<br />prog: Vocational\",\"math: 41<br />num_awards: 1<br />prog: Vocational\",\"math: 39<br />num_awards: 0<br />prog: Vocational\",\"math: 52<br />num_awards: 0<br />prog: Vocational\",\"math: 40<br />num_awards: 0<br />prog: Vocational\",\"math: 45<br />num_awards: 0<br />prog: Vocational\",\"math: 47<br />num_awards: 0<br />prog: Vocational\",\"math: 40<br />num_awards: 1<br />prog: Vocational\",\"math: 52<br />num_awards: 0<br />prog: Vocational\",\"math: 52<br />num_awards: 1<br />prog: Vocational\",\"math: 51<br />num_awards: 1<br />prog: Vocational\",\"math: 55<br />num_awards: 0<br />prog: Vocational\",\"math: 54<br />num_awards: 0<br />prog: Vocational\",\"math: 56<br />num_awards: 0<br />prog: Vocational\",\"math: 46<br />num_awards: 0<br />prog: Vocational\",\"math: 45<br />num_awards: 0<br />prog: Vocational\",\"math: 47<br />num_awards: 0<br />prog: Vocational\",\"math: 41<br />num_awards: 0<br />prog: Vocational\",\"math: 53<br />num_awards: 0<br />prog: Vocational\",\"math: 51<br />num_awards: 1<br />prog: Vocational\",\"math: 40<br />num_awards: 0<br />prog: Vocational\",\"math: 50<br />num_awards: 0<br />prog: Vocational\",\"math: 57<br />num_awards: 0<br />prog: Vocational\",\"math: 57<br />num_awards: 0<br />prog: Vocational\",\"math: 51<br />num_awards: 1<br />prog: Vocational\",\"math: 56<br />num_awards: 2<br />prog: Vocational\",\"math: 53<br />num_awards: 0<br />prog: Vocational\",\"math: 66<br />num_awards: 0<br />prog: Vocational\",\"math: 75<br />num_awards: 2<br />prog: Vocational\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(97,156,255,1)\",\"opacity\":0.5,\"size\":5.6692913385826778,\"symbol\":\"circle\",\"line\":{\"width\":1.8897637795275593,\"color\":\"rgba(97,156,255,1)\"}},\"hoveron\":\"points\",\"name\":\"Vocational\",\"legendgroup\":\"Vocational\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[38,41,41,42,43,43,43,43,44,45,45,45,45,46,48,48,48,48,49,49,49,49,49,49,50,50,50,50,50,51,51,51,51,51,52,52,53,53,53,53,53,54,54,54,54,54,54,55,55,56,56,57,57,57,57,57,57,57,58,58,58,59,59,60,60,60,61,61,61,61,61,62,62,62,62,63,63,63,63,64,64,64,64,64,65,65,65,66,66,66,67,67,68,69,69,70,71,71,71,71,72,72,72,73,75],\"y\":[0.22369446625155454,0.2760931540116035,0.2760931540116035,0.29615729665653001,0.31767953347810174,0.31767953347810174,0.31767953347810174,0.31767953347810174,0.34076582657325905,0.36552983847843945,0.36552983847843945,0.36552983847843945,0.36552983847843945,0.3920934917731535,0.45115235831258743,0.45115235831258743,0.45115235831258743,0.45115235831258743,0.48393834065316477,0.48393834065316477,0.48393834065316477,0.48393834065316477,0.48393834065316477,0.48393834065316477,0.51910693414102083,0.51910693414102083,0.51910693414102083,0.51910693414102083,0.51910693414102083,0.55683128703873208,0.55683128703873208,0.55683128703873208,0.55683128703873208,0.55683128703873208,0.5972971305772995,0.5972971305772995,0.64070369338111477,0.64070369338111477,0.64070369338111477,0.64070369338111477,0.64070369338111477,0.68726468234569316,0.68726468234569316,0.68726468234569316,0.68726468234569316,0.68726468234569316,0.68726468234569316,0.73720933479739625,0.73720933479739625,0.79078354711533239,0.79078354711533239,0.84825108537206206,0.84825108537206206,0.84825108537206206,0.84825108537206206,0.84825108537206206,0.84825108537206206,0.84825108537206206,0.90989488395354856,0.90989488395354856,0.90989488395354856,0.97601843855195658,0.97601843855195658,1.0469473003895149,1.0469473003895149,1.0469473003895149,1.1230306790300921,1.1230306790300921,1.1230306790300921,1.1230306790300921,1.1230306790300921,1.204643161669706,1.204643161669706,1.204643161669706,1.204643161669706,1.2921865573707112,1.2921865573707112,1.2921865573707112,1.2921865573707112,1.3860918753194953,1.3860918753194953,1.3860918753194953,1.3860918753194953,1.3860918753194953,1.4868214468474259,1.4868214468474259,1.4868214468474259,1.5948712016625313,1.5948712016625313,1.5948712016625313,1.7107731094986713,1.7107731094986713,1.8350977992033766,1.9684573681590758,1.9684573681590758,2.1115083958696022,2.2649551765489475,2.2649551765489475,2.2649551765489475,2.2649551765489475,2.4295531866275786,2.4295531866275786,2.4295531866275786,2.6061128042480952,2.9986571119762258],\"text\":[\"math: 38<br />fitted_values: 0.22369447<br />prog: Academic\",\"math: 41<br />fitted_values: 0.27609315<br />prog: Academic\",\"math: 41<br />fitted_values: 0.27609315<br />prog: Academic\",\"math: 42<br />fitted_values: 0.29615730<br />prog: Academic\",\"math: 43<br />fitted_values: 0.31767953<br />prog: Academic\",\"math: 43<br />fitted_values: 0.31767953<br />prog: Academic\",\"math: 43<br />fitted_values: 0.31767953<br />prog: Academic\",\"math: 43<br />fitted_values: 0.31767953<br />prog: Academic\",\"math: 44<br />fitted_values: 0.34076583<br />prog: Academic\",\"math: 45<br />fitted_values: 0.36552984<br />prog: Academic\",\"math: 45<br />fitted_values: 0.36552984<br />prog: Academic\",\"math: 45<br />fitted_values: 0.36552984<br />prog: Academic\",\"math: 45<br />fitted_values: 0.36552984<br />prog: Academic\",\"math: 46<br />fitted_values: 0.39209349<br />prog: Academic\",\"math: 48<br />fitted_values: 0.45115236<br />prog: Academic\",\"math: 48<br />fitted_values: 0.45115236<br />prog: Academic\",\"math: 48<br />fitted_values: 0.45115236<br />prog: Academic\",\"math: 48<br />fitted_values: 0.45115236<br />prog: Academic\",\"math: 49<br />fitted_values: 0.48393834<br />prog: Academic\",\"math: 49<br />fitted_values: 0.48393834<br />prog: Academic\",\"math: 49<br />fitted_values: 0.48393834<br />prog: Academic\",\"math: 49<br />fitted_values: 0.48393834<br />prog: Academic\",\"math: 49<br />fitted_values: 0.48393834<br />prog: Academic\",\"math: 49<br />fitted_values: 0.48393834<br />prog: Academic\",\"math: 50<br />fitted_values: 0.51910693<br />prog: Academic\",\"math: 50<br />fitted_values: 0.51910693<br />prog: Academic\",\"math: 50<br />fitted_values: 0.51910693<br />prog: Academic\",\"math: 50<br />fitted_values: 0.51910693<br />prog: Academic\",\"math: 50<br />fitted_values: 0.51910693<br />prog: Academic\",\"math: 51<br />fitted_values: 0.55683129<br />prog: Academic\",\"math: 51<br />fitted_values: 0.55683129<br />prog: Academic\",\"math: 51<br />fitted_values: 0.55683129<br />prog: Academic\",\"math: 51<br />fitted_values: 0.55683129<br />prog: Academic\",\"math: 51<br />fitted_values: 0.55683129<br />prog: Academic\",\"math: 52<br />fitted_values: 0.59729713<br />prog: Academic\",\"math: 52<br />fitted_values: 0.59729713<br />prog: Academic\",\"math: 53<br />fitted_values: 0.64070369<br />prog: Academic\",\"math: 53<br />fitted_values: 0.64070369<br />prog: Academic\",\"math: 53<br />fitted_values: 0.64070369<br />prog: Academic\",\"math: 53<br />fitted_values: 0.64070369<br />prog: Academic\",\"math: 53<br />fitted_values: 0.64070369<br />prog: Academic\",\"math: 54<br />fitted_values: 0.68726468<br />prog: Academic\",\"math: 54<br />fitted_values: 0.68726468<br />prog: Academic\",\"math: 54<br />fitted_values: 0.68726468<br />prog: Academic\",\"math: 54<br />fitted_values: 0.68726468<br />prog: Academic\",\"math: 54<br />fitted_values: 0.68726468<br />prog: Academic\",\"math: 54<br />fitted_values: 0.68726468<br />prog: Academic\",\"math: 55<br />fitted_values: 0.73720933<br />prog: Academic\",\"math: 55<br />fitted_values: 0.73720933<br />prog: Academic\",\"math: 56<br />fitted_values: 0.79078355<br />prog: Academic\",\"math: 56<br />fitted_values: 0.79078355<br />prog: Academic\",\"math: 57<br />fitted_values: 0.84825109<br />prog: Academic\",\"math: 57<br />fitted_values: 0.84825109<br />prog: Academic\",\"math: 57<br />fitted_values: 0.84825109<br />prog: Academic\",\"math: 57<br />fitted_values: 0.84825109<br />prog: Academic\",\"math: 57<br />fitted_values: 0.84825109<br />prog: Academic\",\"math: 57<br />fitted_values: 0.84825109<br />prog: Academic\",\"math: 57<br />fitted_values: 0.84825109<br />prog: Academic\",\"math: 58<br />fitted_values: 0.90989488<br />prog: Academic\",\"math: 58<br />fitted_values: 0.90989488<br />prog: Academic\",\"math: 58<br />fitted_values: 0.90989488<br />prog: Academic\",\"math: 59<br />fitted_values: 0.97601844<br />prog: Academic\",\"math: 59<br />fitted_values: 0.97601844<br />prog: Academic\",\"math: 60<br />fitted_values: 1.04694730<br />prog: Academic\",\"math: 60<br />fitted_values: 1.04694730<br />prog: Academic\",\"math: 60<br />fitted_values: 1.04694730<br />prog: Academic\",\"math: 61<br />fitted_values: 1.12303068<br />prog: Academic\",\"math: 61<br />fitted_values: 1.12303068<br />prog: Academic\",\"math: 61<br />fitted_values: 1.12303068<br />prog: Academic\",\"math: 61<br />fitted_values: 1.12303068<br />prog: Academic\",\"math: 61<br />fitted_values: 1.12303068<br />prog: Academic\",\"math: 62<br />fitted_values: 1.20464316<br />prog: Academic\",\"math: 62<br />fitted_values: 1.20464316<br />prog: Academic\",\"math: 62<br />fitted_values: 1.20464316<br />prog: Academic\",\"math: 62<br />fitted_values: 1.20464316<br />prog: Academic\",\"math: 63<br />fitted_values: 1.29218656<br />prog: Academic\",\"math: 63<br />fitted_values: 1.29218656<br />prog: Academic\",\"math: 63<br />fitted_values: 1.29218656<br />prog: Academic\",\"math: 63<br />fitted_values: 1.29218656<br />prog: Academic\",\"math: 64<br />fitted_values: 1.38609188<br />prog: Academic\",\"math: 64<br />fitted_values: 1.38609188<br />prog: Academic\",\"math: 64<br />fitted_values: 1.38609188<br />prog: Academic\",\"math: 64<br />fitted_values: 1.38609188<br />prog: Academic\",\"math: 64<br />fitted_values: 1.38609188<br />prog: Academic\",\"math: 65<br />fitted_values: 1.48682145<br />prog: Academic\",\"math: 65<br />fitted_values: 1.48682145<br />prog: Academic\",\"math: 65<br />fitted_values: 1.48682145<br />prog: Academic\",\"math: 66<br />fitted_values: 1.59487120<br />prog: Academic\",\"math: 66<br />fitted_values: 1.59487120<br />prog: Academic\",\"math: 66<br />fitted_values: 1.59487120<br />prog: Academic\",\"math: 67<br />fitted_values: 1.71077311<br />prog: Academic\",\"math: 67<br />fitted_values: 1.71077311<br />prog: Academic\",\"math: 68<br />fitted_values: 1.83509780<br />prog: Academic\",\"math: 69<br />fitted_values: 1.96845737<br />prog: Academic\",\"math: 69<br />fitted_values: 1.96845737<br />prog: Academic\",\"math: 70<br />fitted_values: 2.11150840<br />prog: Academic\",\"math: 71<br />fitted_values: 2.26495518<br />prog: Academic\",\"math: 71<br />fitted_values: 2.26495518<br />prog: Academic\",\"math: 71<br />fitted_values: 2.26495518<br />prog: Academic\",\"math: 71<br />fitted_values: 2.26495518<br />prog: Academic\",\"math: 72<br />fitted_values: 2.42955319<br />prog: Academic\",\"math: 72<br />fitted_values: 2.42955319<br />prog: Academic\",\"math: 72<br />fitted_values: 2.42955319<br />prog: Academic\",\"math: 73<br />fitted_values: 2.60611280<br />prog: Academic\",\"math: 75<br />fitted_values: 2.99865711<br />prog: Academic\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":3.7795275590551185,\"color\":\"rgba(248,118,109,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"Academic\",\"legendgroup\":\"Academic\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[35,39,39,41,41,42,42,42,42,42,43,43,43,44,45,46,46,46,46,48,49,49,49,50,52,54,54,54,55,55,56,56,56,57,57,57,57,58,58,58,60,60,61,61,63],\"y\":[0.061311338470096725,0.081172326521828569,0.081172326521828569,0.093398863557851527,0.093398863557851527,0.10018631226518167,0.10018631226518167,0.10018631226518167,0.10018631226518167,0.10018631226518167,0.10746701601009694,0.10746701601009694,0.10746701601009694,0.1152768204457424,0.12365417618770963,0.13264032812093288,0.13264032812093288,0.13264032812093288,0.13264032812093288,0.15261920458943862,0.16371029267599441,0.16371029267599441,0.16371029267599441,0.17560738833724998,0.202058154618136,0.23249305302165454,0.23249305302165454,0.23249305302165454,0.24938870476818384,0.24938870476818384,0.2675121912574287,0.2675121912574287,0.2675121912574287,0.28695274125534831,0.28695274125534831,0.28695274125534831,0.28695274125534831,0.30780606792877235,0.30780606792877235,0.30780606792877235,0.35416918761133676,0.35416918761133676,0.37990724376166413,0.37990724376166413,0.43713056339703621],\"text\":[\"math: 35<br />fitted_values: 0.06131134<br />prog: General\",\"math: 39<br />fitted_values: 0.08117233<br />prog: General\",\"math: 39<br />fitted_values: 0.08117233<br />prog: General\",\"math: 41<br />fitted_values: 0.09339886<br />prog: General\",\"math: 41<br />fitted_values: 0.09339886<br />prog: General\",\"math: 42<br />fitted_values: 0.10018631<br />prog: General\",\"math: 42<br />fitted_values: 0.10018631<br />prog: General\",\"math: 42<br />fitted_values: 0.10018631<br />prog: General\",\"math: 42<br />fitted_values: 0.10018631<br />prog: General\",\"math: 42<br />fitted_values: 0.10018631<br />prog: General\",\"math: 43<br />fitted_values: 0.10746702<br />prog: General\",\"math: 43<br />fitted_values: 0.10746702<br />prog: General\",\"math: 43<br />fitted_values: 0.10746702<br />prog: General\",\"math: 44<br />fitted_values: 0.11527682<br />prog: General\",\"math: 45<br />fitted_values: 0.12365418<br />prog: General\",\"math: 46<br />fitted_values: 0.13264033<br />prog: General\",\"math: 46<br />fitted_values: 0.13264033<br />prog: General\",\"math: 46<br />fitted_values: 0.13264033<br />prog: General\",\"math: 46<br />fitted_values: 0.13264033<br />prog: General\",\"math: 48<br />fitted_values: 0.15261920<br />prog: General\",\"math: 49<br />fitted_values: 0.16371029<br />prog: General\",\"math: 49<br />fitted_values: 0.16371029<br />prog: General\",\"math: 49<br />fitted_values: 0.16371029<br />prog: General\",\"math: 50<br />fitted_values: 0.17560739<br />prog: General\",\"math: 52<br />fitted_values: 0.20205815<br />prog: General\",\"math: 54<br />fitted_values: 0.23249305<br />prog: General\",\"math: 54<br />fitted_values: 0.23249305<br />prog: General\",\"math: 54<br />fitted_values: 0.23249305<br />prog: General\",\"math: 55<br />fitted_values: 0.24938870<br />prog: General\",\"math: 55<br />fitted_values: 0.24938870<br />prog: General\",\"math: 56<br />fitted_values: 0.26751219<br />prog: General\",\"math: 56<br />fitted_values: 0.26751219<br />prog: General\",\"math: 56<br />fitted_values: 0.26751219<br />prog: General\",\"math: 57<br />fitted_values: 0.28695274<br />prog: General\",\"math: 57<br />fitted_values: 0.28695274<br />prog: General\",\"math: 57<br />fitted_values: 0.28695274<br />prog: General\",\"math: 57<br />fitted_values: 0.28695274<br />prog: General\",\"math: 58<br />fitted_values: 0.30780607<br />prog: General\",\"math: 58<br />fitted_values: 0.30780607<br />prog: General\",\"math: 58<br />fitted_values: 0.30780607<br />prog: General\",\"math: 60<br />fitted_values: 0.35416919<br />prog: General\",\"math: 60<br />fitted_values: 0.35416919<br />prog: General\",\"math: 61<br />fitted_values: 0.37990724<br />prog: General\",\"math: 61<br />fitted_values: 0.37990724<br />prog: General\",\"math: 63<br />fitted_values: 0.43713056<br />prog: General\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":3.7795275590551185,\"color\":\"rgba(0,186,56,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"General\",\"legendgroup\":\"General\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[33,37,38,39,39,39,39,40,40,40,40,40,40,40,40,40,40,41,41,41,42,44,44,45,45,45,46,46,46,47,47,47,49,50,51,51,51,52,52,52,53,53,54,55,56,56,57,57,66,75],\"y\":[0.07712821967756274,0.10211287484398918,0.10953358505351223,0.11749357045333669,0.11749357045333669,0.11749357045333669,0.11749357045333669,0.12603202105663702,0.12603202105663702,0.12603202105663702,0.12603202105663702,0.12603202105663702,0.12603202105663702,0.12603202105663702,0.12603202105663702,0.12603202105663702,0.12603202105663702,0.13519097487916629,0.13519097487916629,0.13519097487916629,0.14501552490827807,0.1668584085862834,0.1668584085862834,0.17898428299764205,0.17898428299764205,0.17898428299764205,0.19199136460428576,0.19199136460428576,0.19199136460428576,0.20594369217939318,0.20594369217939318,0.20594369217939318,0.23696384754095642,0.25418439926297609,0.27265639674217818,0.27265639674217818,0.27265639674217818,0.2924707845956952,0.2924707845956952,0.2924707845956952,0.31372511653525115,0.31372511653525115,0.33652403566091299,0.3609797896585768,0.38721278343770121,0.38721278343770121,0.41535217193013207,0.41535217193013207,0.78094001762319454,1.4683137644165336],\"text\":[\"math: 33<br />fitted_values: 0.07712822<br />prog: Vocational\",\"math: 37<br />fitted_values: 0.10211287<br />prog: Vocational\",\"math: 38<br />fitted_values: 0.10953359<br />prog: Vocational\",\"math: 39<br />fitted_values: 0.11749357<br />prog: Vocational\",\"math: 39<br />fitted_values: 0.11749357<br />prog: Vocational\",\"math: 39<br />fitted_values: 0.11749357<br />prog: Vocational\",\"math: 39<br />fitted_values: 0.11749357<br />prog: Vocational\",\"math: 40<br />fitted_values: 0.12603202<br />prog: Vocational\",\"math: 40<br />fitted_values: 0.12603202<br />prog: Vocational\",\"math: 40<br />fitted_values: 0.12603202<br />prog: Vocational\",\"math: 40<br />fitted_values: 0.12603202<br />prog: Vocational\",\"math: 40<br />fitted_values: 0.12603202<br />prog: Vocational\",\"math: 40<br />fitted_values: 0.12603202<br />prog: Vocational\",\"math: 40<br />fitted_values: 0.12603202<br />prog: Vocational\",\"math: 40<br />fitted_values: 0.12603202<br />prog: Vocational\",\"math: 40<br />fitted_values: 0.12603202<br />prog: Vocational\",\"math: 40<br />fitted_values: 0.12603202<br />prog: Vocational\",\"math: 41<br />fitted_values: 0.13519097<br />prog: Vocational\",\"math: 41<br />fitted_values: 0.13519097<br />prog: Vocational\",\"math: 41<br />fitted_values: 0.13519097<br />prog: Vocational\",\"math: 42<br />fitted_values: 0.14501552<br />prog: Vocational\",\"math: 44<br />fitted_values: 0.16685841<br />prog: Vocational\",\"math: 44<br />fitted_values: 0.16685841<br />prog: Vocational\",\"math: 45<br />fitted_values: 0.17898428<br />prog: Vocational\",\"math: 45<br />fitted_values: 0.17898428<br />prog: Vocational\",\"math: 45<br />fitted_values: 0.17898428<br />prog: Vocational\",\"math: 46<br />fitted_values: 0.19199136<br />prog: Vocational\",\"math: 46<br />fitted_values: 0.19199136<br />prog: Vocational\",\"math: 46<br />fitted_values: 0.19199136<br />prog: Vocational\",\"math: 47<br />fitted_values: 0.20594369<br />prog: Vocational\",\"math: 47<br />fitted_values: 0.20594369<br />prog: Vocational\",\"math: 47<br />fitted_values: 0.20594369<br />prog: Vocational\",\"math: 49<br />fitted_values: 0.23696385<br />prog: Vocational\",\"math: 50<br />fitted_values: 0.25418440<br />prog: Vocational\",\"math: 51<br />fitted_values: 0.27265640<br />prog: Vocational\",\"math: 51<br />fitted_values: 0.27265640<br />prog: Vocational\",\"math: 51<br />fitted_values: 0.27265640<br />prog: Vocational\",\"math: 52<br />fitted_values: 0.29247078<br />prog: Vocational\",\"math: 52<br />fitted_values: 0.29247078<br />prog: Vocational\",\"math: 52<br />fitted_values: 0.29247078<br />prog: Vocational\",\"math: 53<br />fitted_values: 0.31372512<br />prog: Vocational\",\"math: 53<br />fitted_values: 0.31372512<br />prog: Vocational\",\"math: 54<br />fitted_values: 0.33652404<br />prog: Vocational\",\"math: 55<br />fitted_values: 0.36097979<br />prog: Vocational\",\"math: 56<br />fitted_values: 0.38721278<br />prog: Vocational\",\"math: 56<br />fitted_values: 0.38721278<br />prog: Vocational\",\"math: 57<br />fitted_values: 0.41535217<br />prog: Vocational\",\"math: 57<br />fitted_values: 0.41535217<br />prog: Vocational\",\"math: 66<br />fitted_values: 0.78094002<br />prog: Vocational\",\"math: 75<br />fitted_values: 1.46831376<br />prog: Vocational\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":3.7795275590551185,\"color\":\"rgba(97,156,255,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"Vocational\",\"legendgroup\":\"Vocational\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":26.228310502283104,\"r\":7.3059360730593621,\"b\":40.182648401826491,\"l\":31.415525114155255},\"plot_bgcolor\":\"rgba(235,235,235,1)\",\"paper_bgcolor\":\"rgba(255,255,255,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[30.886676403358578,77.379795529469845],\"tickmode\":\"array\",\"ticktext\":[\"40\",\"50\",\"60\",\"70\"],\"tickvals\":[40,50,60,70],\"categoryorder\":\"array\",\"categoryarray\":[\"40\",\"50\",\"60\",\"70\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.6529680365296811,\"tickwidth\":0.66417600664176002,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.68949771689498},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176002,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Math Score\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-0.50893455613404515,6.309824918396771],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"2\",\"4\",\"6\"],\"tickvals\":[0,2,4,6],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"2\",\"4\",\"6\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.6529680365296811,\"tickwidth\":0.66417600664176002,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.68949771689498},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176002,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Expected number of awards\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":true,\"legend\":{\"bgcolor\":\"rgba(255,255,255,1)\",\"bordercolor\":\"transparent\",\"borderwidth\":1.8897637795275593,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.68949771689498},\"title\":{\"text\":\"prog\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"736c3a8a563c\":{\"x\":{},\"y\":{},\"colour\":{},\"type\":\"scatter\"},\"736c5178ffe\":{\"x\":{},\"y\":{},\"colour\":{}}},\"cur_data\":\"736c3a8a563c\",\"visdat\":{\"736c3a8a563c\":[\"function (y) \",\"x\"],\"736c5178ffe\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- This graph indicates that the most awards are earned by students in the `academic` program, especially if the student has a high math score. \n\n- Students in the `general program` earn the lowest number of awards\n\n## CI of cofficients\n\n- Construct and interpret the confidence intervals for each variable using `confint()`.\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nWaiting for profiling to be done...\n```\n\n\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>beta interval</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> 2.5 % </th>\n   <th style=\"text-align:right;\"> 97.5 % </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -5.4857279 </td>\n   <td style=\"text-align:right;\"> -2.8857230 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> progGeneral </td>\n   <td style=\"text-align:right;\"> -1.8558691 </td>\n   <td style=\"text-align:right;\"> -0.4350439 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> progVocational </td>\n   <td style=\"text-align:right;\"> -1.3905775 </td>\n   <td style=\"text-align:right;\"> -0.1261624 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> math </td>\n   <td style=\"text-align:right;\"> 0.0494967 </td>\n   <td style=\"text-align:right;\"> 0.0910770 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>beta interval</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> 2.5 % </th>\n   <th style=\"text-align:right;\"> 97.5 % </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -99.585448 </td>\n   <td style=\"text-align:right;\"> -94.418558 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> progGeneral </td>\n   <td style=\"text-align:right;\"> -84.368296 </td>\n   <td style=\"text-align:right;\"> -35.276377 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> progVocational </td>\n   <td style=\"text-align:right;\"> -75.106849 </td>\n   <td style=\"text-align:right;\"> -11.852828 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> math </td>\n   <td style=\"text-align:right;\"> 5.074217 </td>\n   <td style=\"text-align:right;\"> 9.535332 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- at $\\alpha = 0.05$, Compared to the students in `academic program`, the mean number of awards that students in `General program` decreases by 35% to 84% holding the math score constant.\n\n- With 95% confidence, the mean number of awards decrease by 11% to 75% for the student in `vocational program` vs. student in `academic programs`, holding the math score constant.\n\n-  95% confidence interval of a the effect of 1-unit increase in math score on the mean number of award holding everything else constant is `5.07% to 9.53% increase` \n\n\n\\newpage\n\n# Model Comparison Criteria\n\nRecall that the general form of most information criteria is:\n\n$$\\text{IC}(k)=-2log(L(\\hat{\\beta}|y_1,.....,y_n))+kr$$\n\nWhere \n\n- $\\text{log}(L(\\hat{\\beta}|y_1,.....,y_n))$ is the log-likelihood of an estimated model, - `n` is the sample size, \n- `r` is the number of parameters in the model, \n- `k` is a penalty term on the number of parameters. \n\nThe three most common information criteria are:\n\n## AIC\n\n$$AIC = IC(2) = -2log(L(\\hat{\\beta}|y_1,.....,y_n))+2r$$\n\n## AIC_c\n\n$$AIC_c = IC(\\frac{2n}{n-r-1}) = -2log(L(\\hat{\\beta}|y_1,.....,y_n))+r\\frac{2n}{n-r-1}=AIC+\\frac{2r(r+1)}{n-r-1}$$\n\n## BIC\n\n$$BIC = IC(log(n)) = -2log(L(\\hat{\\beta}|y_1,.....,y_n))+rlog(n)$$\n\n## Example\n\n- Compute these three information criteria for the following three models and then rank the models based on each criterion using `AIC()`, `BIC()`, and `AICc()`.  \n\n$$\\text{mod.1:   }\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 prog + u  $$\n$$\\text{mod.2:   }\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 math + u$$\n\n$$\\text{mod.3:   }\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 prog + \\beta_2 math + u$$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n     mod.1    mod.2    mod.3\n1 384.0762 416.5149 373.5045\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     mod.1    mod.2    mod.3\n1 384.1371 416.6373 373.7096\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     mod.1    mod.2    mod.3\n1 390.6728 426.4098 386.6978\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- The model with the `lowest` AIC, corrected AIC, or BIC score is preferred. \n  - The absolute values of these scores do not matter.\n\n- These scores can be negative or positive.\n  - Based on all these three criteria, the third model with both math and program is the best, and the second model with the only program is the worst model\n\n\n# Model Assessment\n\nRecall that the Pearson residuals correct for unequal variance in the raw residuals by dividing by the standard deviation:\n\n$$e_m = \\frac{y_m - \\widehat{y_m}}{\\sqrt{\\widehat{\\text{V}(Y_m)}}}$$\n\nStandardized Pearson residuals also correct for overestimates of the standard deviation of $y_m - \\widehat{y_m}$:\n\n$$r_m = \\frac{y_m - \\widehat{y_m}}{\\sqrt{\\widehat{\\text{V}(Y_m-\\hat{Y_m})}}}=\\frac{y_m - \\widehat{y_m}}{\\sqrt{\\widehat{\\text{V}(Y_m)}-(1-h_m)}}$$\nwhere $h_m$ is the mth diagonal element of the hat matrix.\n\n- For the first Poisson model using `prog` and `math` as predictors, plot the standardized Pearson residuals against explanatory variables, fitted values, and the linear predictor to assess whether the model assumptions are satisfied. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](wk5_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](wk5_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](wk5_files/figure-html/unnamed-chunk-15-3.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe have four assumptions general assumptions for Poisson regression\n\n- 1. IID data.\n- 2. The distribution of the response is the one specified by the model, which here is Poisson.\n- 3. The mean of the distribution is linked to the explanatory variables by the `link function` that we specify. In Poisson is is log().\n\n- 4. The link relates to the explanatory variables in a `linear fashion`. Here linearity means using a linear combination of the regression parameters.\n  - For `iid data`, we must discuss how the data is generated and look for possible clustering. \n    - Here there could be some clustering among the students who are in the same program or same classroom, or same cohort, which would violate independence.\n\n  - The plot of the standardized residuals against `math` shows roughly the same variance throughout the math score range. \n    - There is no severe curvature in the plot, suggesting we don’t need a transformation or additional polynomial terms.\n\n    - Similarly, the plots of `residuals against the fitted values` and `linear predictor` have roughly constant variance. \n      - They show no evident curvature, so we can conclude that the link function fits well here.\n\n- We can also use these plots to check for `extreme residuals`. In this case, there are numerous residuals whose magnitudes are larger than 2 or 3, scattered across the range of math scores. \n\n- This may be a sign of `overdispersion`, meaning more variability in the\ncounts than the model estimated. \n\n- This is an indication that there may be important explanatory variables missing from the model\n\n\n\n\\newpage\n\n# Goodness of Fit\n\n$$H_0: \\text{Our Model is correct}$$\n- The Pearson Statistic $\\chi^2$ and Residual Deviance $D$ are often used to test the goodness of fit, where the null hypothesis is that our model is correct. Under asymptotic theory, both of these follow a chi-squared distribution with the same degrees of freedom as the residuals from the Poisson model.\n\nWe can also use these to test for overdispersion in our model since if our model is a good fit to the data we should not have overdispersion.\n\n## The Pearson Statistics\n\n\n$$\\chi^2=\\sum_{i=1}^{n}\\frac{(y_{i}-\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\})^{2}}{\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\}}$$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate Pearson statistic residuals\npearson_stat <- sum(residuals(poisson.mod.1, type = \"pearson\")^2)\npearson_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 212.1437\n```\n\n\n:::\n\n```{.r .cell-code}\n# Get p value associated with the pearson statistic\npearson_p.value <- pchisq(pearson_stat, poisson.mod.1$df.residual,\nlower.tail = FALSE)\npearson_p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.203986\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Residual Deviance \n\n$$D=2\\sum_{i=1}^{n}\\biggl[y_{i}\\log\\biggl(\\frac{y_{i}}{\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\}}\\biggr)-(y_{i}-\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\})\\biggr]$$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6182274\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- `Goodness-of-fit statistics` test is a more objective measure of the overall fit.\n\n- The null hypothesis is that the model is correct against the alternative that it is not.\n- We can use both Pearson statistic or the residual deviance to perform this test\n\n- Here, the two non significant p-values indicate that we `fail to reject the null hypothesis that the model is correct`\n\n\n\\newpage\n\n# Directly Testing for Over Dispersion\n\nWe can use a dispersion test for Poisson regression from the AER package that tests the null hypothesis that \n\n$$\\theta=1$$ \n\nvs. not in a regression of the form \n\n$$\\text{V}(Y_i)=(1+\\alpha)*\\lambda_i$$\n\n- Note that if we set $(1+\\alpha)=\\theta$ we get the variance form for a quasipoisson above. \n\n- So this test is examining whether the variance of our outcome variable appears to come from a Poisson or quasipoisson distribution.\n\nIf we reject the null hypothesis due to a small p-value, we have overdispersion if $\\alpha>0$ and underdispersion (smaller variance in reality which is less common) if $\\alpha<0$.\n\nThe test itself reports the estimated dispersion value along with a p-value.\n\nRun the test using `dispersiontest()`:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# replace with your code\ndispersiontest(poisson.mod.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOverdispersion test\n\ndata:  poisson.mod.1\nz = 0.53224, p-value = 0.2973\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n  1.047254 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- Note the dispersion estimate above 1 but lack of significant `p-value` since it is larger than 0.05. \n  - This means we fail to reject the $H_0$ that poission regression is value.\n\n- If we reject the $H_0$ in an overdispersion test, that means we should fit a quasipoisson or `negative binomial regression`.\n\n- We can fit quasipoisson directly using `glm()` and specifying the appropriate family. \n- For a negative binomial using regression, we need to use `glm.nb()` from the MASS package.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n===========================================================\n                             Dependent variable:           \n                  -----------------------------------------\n                                 num_awards                \n                   Poisson  glm: quasipoisson   negative   \n                               link = log       binomial   \n                     (1)           (2)             (3)     \n-----------------------------------------------------------\nprogGeneral       -1.084***     -1.084***       -1.075***  \n                   (0.358)       (0.373)         (0.367)   \n                                                           \nprogVocational    -0.714**      -0.714**        -0.708**   \n                   (0.320)       (0.333)         (0.334)   \n                                                           \nmath              0.070***      0.070***        0.071***   \n                   (0.011)       (0.011)         (0.012)   \n                                                           \nConstant          -4.163***     -4.163***       -4.218***  \n                   (0.663)       (0.690)         (0.713)   \n                                                           \n-----------------------------------------------------------\nObservations         200           200             200     \nLog Likelihood    -182.752                      -182.905   \ntheta                                         6.115 (5.577)\nAkaike Inf. Crit.  373.505                       373.811   \n===========================================================\nNote:                           *p<0.1; **p<0.05; ***p<0.01\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\newpage\n\n## Reminders\n\n1. Before next live session: \n    1. Complete and turn in the Lab-1\n    2. Complete all videos and reading for unit 6\n\n",
    "supporting": [
      "wk5_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n<link href=\"site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"site_libs/plotly-binding-4.10.4/plotly.js\"></script>\n<script src=\"site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n<link href=\"site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}