{"title":"Possion regression","markdown":{"yaml":{"title":"Possion regression","format":{"html":{"toc":true,"html-math-method":"katex","css":"style.css","theme":{"light":"cosmo","dark":["cosmo","theme-dark.scss"]}}},"execute":{"echo":false},"editor_options":{"chunk_output_type":"console"}},"headingText":"Generalized linear models (GLM)","containsRefs":false,"markdown":"\n\n\n\n```{=html}\n<style>\n.table-hover > tbody > tr:hover { \n  background-color: #f4f442;\n}\n</style>\n```\n\n```{r message=FALSE, warning=FALSE, include=FALSE}\nlibrary(here)\nsource(here(\"source\",\"get_lib.R\"))\n```\n\n\nReading\n- Ch 4.1,4.2.1 - 4.2.3,5.2\n- Skim sections 5.1, 5.2.3,5.3,.5.4\n  \n\n- GLMs have three different parts (see page 121:\n  \n  1. Random Component:\n      - $Y$, for logistic regression, $Y$ has a Bernoulli distribution\n  \n  2. Systematic Component:\n      - This specifies a linear combination of the regression parameters with `features`, and this part is referred to as the `linear predictor`\n      - $\\beta_0 + \\beta_1x_1 + .... + \\beta_px_p$\n      \n  3. LINK FUNCTION:\n      - Specifies how the expected value of the `random component` $E[Y]$ is linked to the `sysmatic` component.\n      - $\\text{logit}(\\pi) = \\beta_0 + \\beta_1x_1 + .... + \\beta_px_p$\n      - where $E[Y] = \\pi$\n\n\n## Class Announcements\n\nNo HW this week\n\nLab-1 due in 1 week\n\n## Roadmap\n\n**Rearview Mirror**\n\n- Model unordered and ordered categorical response \n\n**Today**\n\n- Poisson probability model\n\n- Poisson regression model, estimation, and statistical inference\n\n- Model Comparison Criteria, Model Assessment, Goodness of Fit\n\n**Looking Ahead**\n\n- Univariate and multivariate time-series\n\n- Notion of dependency and stationarity\n\n# Poisson Distribution \n\nRecall that the Poisson distribution models count data i.e. the number of events between 0,1,... for a random variable $X$. The distribution is:\n\n$$P(X=k)=\\frac{\\lambda^ke^{-\\lambda}}{k!}$$\nOne key assumption of the distribution is that $E(X)=Var(X)=\\lambda$, meaning that the mean and variance of the distribution is the same.\n\nAs we will see this is a limiting assumption when we do Poisson Regression.\n\n\nIn Poisson regression we model the log of $\\lambda$ (the mean assuming a Poisson distribution) as a linear combination of the features:\n\n$$\\text{log}(\\lambda_i)=\\text{log}(E(Y_i|X_i))=X_i\\beta$$\n\nWe use maximum likelihood to estimate the coefficients in $\\beta$ assuming that $Y$ follows an iid Poisson distribution:\n\n$$max_\\beta\\ L(\\beta|Y_1,...,Y_n)=P(Y_1=y_1,...,Y_n=y_n|\\beta)=\\Pi_i\\frac{e^{y_iX_i\\beta}e^{-e^{X_i\\beta}}}{y_i!}$$\n\nThe log likelihood has no closed form solution, so we estimate the parameters beta using numerical methods just like in logistic regression.\n\nFor each $y_i$ we can calculate and predict fitted values using the MLE of the coefficients:\n\n$$\\hat{y_i}=E(y_i|X_i)=\\lambda_i=e^{X_i\\beta}$$\nUnder Poisson regression, the $\\text{V}[\\hat{y_i}]=\\lambda_i=e^{X_i\\beta}$ so that Poisson regression naturally has heteroskedasticity in the results.\n\nBecause coefficients are linear on the log scale, when exponentiated they multiply the expected mean outcome. This is similar to the interpretation in logistic regression except we are not dealing with odds ratios but rather changes in the average outcome.\n\n## Parameter\n\nEqual Mean and Variance and Overdispersion\n\nThis assumption of equal mean and variance is often not met when actually fitting to data, which results in what is known as overdispersion where the variance in the data is larger than the variance fit in the model.\n\nThis usually can be remedied by adding more $X$ variables into the model to improve the fit.\n\nAnother option is to fit what are known as a quasi poisson model or negative binomial regression model. In both cases, we relax the equal mean and variance assumption by adding an additional parameter to the variance of the response variable, allowing it to be larger than the mean.\n\nIn quasi poisson regression we set $\n\n$$\\text{V}[\\hat{y_i}]=\\theta\\lambda_i$$ \nand in negative binomial regression we set \n\n$$\\text{V}[\\hat{y_i}]=\\lambda_i+\\kappa\\lambda_i^2$$\n\n\n# Case Study: Modeling the Number of Awards \n\n## Target\n\n  - `The number of awards` earned by students based on the `type of programs students were enrolled` in using historical admission data. \n  - `num_awards`: the number of awards earned by students at a high school in a year\n  - `math`: students’ scores on their final math exam\n  - `prog`: the type of program in which the students were enrolled \n    - `1 = General`\n    - `2 = Academic` \n    - `3 = Vocational`\n\n## EDA\n\n- What is the number of observations?\n- What is the number of variables? \n- Are there any redundant variables?\n- Are there any missing information?\n- Are there any duplicated records?\n- Are there any values in each of the variables that seem unreasonable?\n\n```{r}\ndf <- read.csv(\"./data/PossionEx1.csv\", \n               stringsAsFactors = F, \n               header=TRUE, sep=\",\")\n\nhead(df) %>%\n  kable(\"html\", caption = \"Modeling the Number of Awards\") %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n#str(df)\n\n## convert prog to factor\ndf$prog = factor(df$prog)\n  \n\n# Checking the number of missing values for each of the variables\n# df[!complete.cases(df),]\nsapply(df, function(x) sum(is.na(x)))\n\n```\n\n\\newpage\n\n### Univariate Analysis\n\n- Use a frequency table and a bar plot to explore the distribution of the response variable(num_awards). What do you learn?\n\n```{r}\n#| echo: false\ndf %>%\n  count(num_awards) %>%\n  mutate(prop = round(prop.table(n),2)) %>%\n  kable(\"html\", caption = \"Modeling the Number of Awards\",\n        col.names = c('Number of awards', 'N', \"Proportion\")) %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n  \n\ndf %>%\n  ggplot(aes(x= num_awards, y = ..prop.., group = 1)) + \n  geom_bar(fill = 'DarkBlue', color = 'black') +\n  geom_text(stat='count', aes(label=..count..), vjust= -1) + \n  xlab(\"Number of awards\") +\n  ylab(\"Proportion\") +\n  ylim(0,1)\n\n```\n\n- The prog is the committee’s key explanatory variable of interest. It has three levels: academic, general, and vocational. Use a frequency table and a bar plot to examine its distribution. What do you discover? \n\n```{r}\n#| echo: false\n#| \ndf %>%\n  count(prog) %>%\n  mutate(prop = round(prop.table(n),2)) %>%\n  kable(\"html\", caption = \"Modeling the Number of Awards\",\n        col.names = c(' Type of program', 'N', \"Proportion\")) %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\ndf %>%\n  ggplot(aes(x= prog, y = ..prop.., group = 1)) + \n  geom_bar(fill = 'DarkBlue', color = 'black') +\n  geom_text(stat='count', aes(label=..count..), vjust=-1) + \n  xlab(\"Type of program\") +\n  ylab(\"Proportion\") +\n  ylim(0,1)\n```\n\n- Plot the distribution of math scores. What are the range and average math scores?\n\n```{r warning=FALSE, error=FALSE, message=FALSE}\n#| echo: false\n\ndf %>% \n  ggplot(aes(x = math)) +\n  geom_histogram(aes(y = ..density..), binwidth = 5 ,fill = \"DarkBlue\", color = \"black\") +\n  geom_vline(aes(xintercept = mean(math)), color = \"red\", linetype = \"dashed\") +\n  ggtitle(\"Distribution of students’ math scores\") + \n  theme(plot.title = element_text(lineheight=1, face=\"bold\")) +\n  xlab(\"Socre\") +\n  ylab(\"Density\")\n\n```\n\n### Bivariate Analysis\n\n- Examine the associations between the number of awards and program and math scores.\n\n- The graph below shows the distribution of the number of awards by program types. How are awards distributed among different programs?\n```{r}\n#| echo: false\ndf %>% \n  ggplot(aes(x = num_awards)) +\n  geom_bar(aes(color = prog, fill = prog),alpha=0.2, position = \"dodge\" ) +\n  ggtitle(\"Distribution of the Number of Awards by Program Types\") + \n  xlab(\"Award\") +\n  ylab(\"Count\")\n\n```\n\n- The graph below shows the distribution of the number of awards and students' math scores. Is there any clear relationship between them?\n\n```{r}\n#| echo: false\ndf %>%\n  ggplot(aes(num_awards, math)) +\n  geom_boxplot(aes(fill = factor(num_awards))) + \n  geom_jitter()+\n  coord_flip() +\n  ggtitle(\"Math Score by the Number of Awards\") + \n  theme(plot.title = element_text(lineheight=1, face=\"bold\")) +\n  xlab(\"Number of Awards\") +\n  ylab(\"Math Score\") \n```\n\n- Use summary_factorlist() function from the finalfit package to tabulate data. What do you learn from the EDA?\n\n```{r}\n#| echo: false\ndependent <- \"num_awards\"\nexplanatory <- c(\"prog\", \"math\")\ndf %>% \n  summary_factorlist(dependent, explanatory, add_dependent_label = TRUE) %>%\n  kable(\"html\", caption = \"Modeling the Number of Awards\") %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n\n# Model Development\n\n- Given the specification of a poisson regression model below,\n\n$$\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 prog + \\beta_2 math + u$$\n\n- Estimate and interpret the model results using `glm()` and the correct `family` parameter:\n\n## Coefficients\n\n```{r}\n#| echo: true\npoisson.mod.1 <- poisson.mod.1 <- glm(num_awards ~ prog + math, \n                                      data = df, \n                                      family = poisson)\n\nsummary(poisson.mod.1)\n```\n\n- The `negative coefficients` of the `general` and `vocational programs` indicate that the number of wards is lower in these two programs.\n\n- The positive coefficients of `math` score indicates that the number of awards is increasing as the math score increases.\n\n```{r}\n#| echo: true\n\n(exp(coef(poisson.mod.1)) - 1) * 100\n```\n\nTo have a more convenient way to interpret these coefficients, we compute and use percentage changes\n  - Holding `program type constant`, 1 unit increase in math score increase the mean number of awards by 7%.\n\n  - Hold `math score constant`; \n    - a student in the `general program`, on average, receives 66% fewer awards than students in the `academic program`\n    - a student in the `vocational program`, on average, receives 51% fewer awards than students in the academic program\n\n### Anova()\n\n- Test the overall effect of prog using `Anova()`:   \n\n```{r}\n## test model differences with chi square test\nAnova(poisson.mod.1)\n```\n\n- Based on the p-values, the prog, taken together, is a statistically significant predictor of the number of awards.\n\n\n## Plot the result \n\n- Plot the fitted values across the three programs and discuss how the number of awards is associated with math scores.\n\n```{r}\n# uncomment and run the code\n\n## calculate and store predicted values\nfitted_values <- predict(poisson.mod.1, type=\"response\")\n\n## create the plot\n\np <- ggplot(df, aes(x = math, y = fitted_values, colour = prog)) +\n geom_point(aes(y = num_awards), alpha=.5, position=position_jitter(h=.2)) +\n geom_line(size = 1) +\n labs(x = \"Math Score\", y = \"Expected number of awards\")\n\nggplotly(p)\n```\n\n- This graph indicates that the most awards are earned by students in the `academic` program, especially if the student has a high math score. \n\n- Students in the `general program` earn the lowest number of awards\n\n## CI of cofficients\n\n- Construct and interpret the confidence intervals for each variable using `confint()`.\n    \n```{r}\n# Confident intervals for the original coefficient estimates\nbeta.interval <- confint(poisson.mod.1, level = 0.95)\n\nbeta.interval %>% kable(\"html\", caption = \"beta interval\") %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n# Convert the confidence intervals to percentage change, corresponding to the coefficient estimates\n\nas.data.frame(100 * (exp(beta.interval) - 1)) %>% \n  kable(\"html\", caption = \"beta interval\") %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n```\n\n- at $\\alpha = 0.05$, Compared to the students in `academic program`, the mean number of awards that students in `General program` decreases by 35% to 84% holding the math score constant.\n\n- With 95% confidence, the mean number of awards decrease by 11% to 75% for the student in `vocational program` vs. student in `academic programs`, holding the math score constant.\n\n-  95% confidence interval of a the effect of 1-unit increase in math score on the mean number of award holding everything else constant is `5.07% to 9.53% increase` \n\n\n\\newpage\n\n# Model Comparison Criteria\n\n[LINK1](https://stats.stackexchange.com/questions/232465/how-to-compare-models-on-the-basis-of-aic)\n[LINK2](https://www.scribbr.com/statistics/akaike-information-criterion/)\n\nRecall that the general form of most information criteria is:\n\n$$\\text{IC}(k)=-2log(L(\\hat{\\beta}|y_1,.....,y_n))+kr$$\n\nWhere \n\n- $\\text{log}(L(\\hat{\\beta}|y_1,.....,y_n))$ is the log-likelihood of an estimated model, - `n` is the sample size, \n- `r` is the number of parameters in the model, \n- `k` is a penalty term on the number of parameters. \n\nThe three most common information criteria are:\n\n## AIC\n\n$$AIC = IC(2) = -2log(L(\\hat{\\beta}|y_1,.....,y_n))+2r$$\n\n## AIC_c\n\n$$AIC_c = IC(\\frac{2n}{n-r-1}) = -2log(L(\\hat{\\beta}|y_1,.....,y_n))+r\\frac{2n}{n-r-1}=AIC+\\frac{2r(r+1)}{n-r-1}$$\n\n## BIC\n\n$$BIC = IC(log(n)) = -2log(L(\\hat{\\beta}|y_1,.....,y_n))+rlog(n)$$\n\n## Example\n\n- Compute these three information criteria for the following three models and then rank the models based on each criterion using `AIC()`, `BIC()`, and `AICc()`.  \n\n$$\\text{mod.1:   }\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 prog + u  $$\n$$\\text{mod.2:   }\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 math + u$$\n\n$$\\text{mod.3:   }\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 prog + \\beta_2 math + u$$\n\n```{r}\n## fit models\nmod.1 <- glm(num_awards ~ math, data = df, family = poisson)\nmod.2 <- glm(num_awards ~ prog, data = df, family = poisson)\nmod.3 <- glm(num_awards ~ prog + math, data = df, family = poisson)\n\n## compute AIC\ndata.frame(mod.1 = AIC(mod.1, k = 2), mod.2 = AIC(mod.2), mod.3 = AIC(mod.3))\n\n## compute corrected AIC \ndata.frame(mod.1 = AICc(mod.1), mod.2 = AICc(mod.2), mod.3 = AICc(mod.3))\n\n## compute BIC\ndata.frame(mod.1 = BIC(mod.1), mod.2 = BIC(mod.2), mod.3 = BIC(mod.3))\n```\n\n- The model with the `lowest` AIC, corrected AIC, or BIC score is preferred. \n  - The absolute values of these scores do not matter.\n\n- These scores can be negative or positive.\n  - Based on all these three criteria, the third model with both math and program is the best, and the second model with the only program is the worst model\n\n\n# Model Assessment\n\nRecall that the Pearson residuals correct for unequal variance in the raw residuals by dividing by the standard deviation:\n\n$$e_m = \\frac{y_m - \\widehat{y_m}}{\\sqrt{\\widehat{\\text{V}(Y_m)}}}$$\n\nStandardized Pearson residuals also correct for overestimates of the standard deviation of $y_m - \\widehat{y_m}$:\n\n$$r_m = \\frac{y_m - \\widehat{y_m}}{\\sqrt{\\widehat{\\text{V}(Y_m-\\hat{Y_m})}}}=\\frac{y_m - \\widehat{y_m}}{\\sqrt{\\widehat{\\text{V}(Y_m)}-(1-h_m)}}$$\nwhere $h_m$ is the mth diagonal element of the hat matrix.\n\n- For the first Poisson model using `prog` and `math` as predictors, plot the standardized Pearson residuals against explanatory variables, fitted values, and the linear predictor to assess whether the model assumptions are satisfied. \n\n```{r message=FALSE, warning=FALSE}\n#| echo: false\npred <- predict(poisson.mod.1, type = \"response\")\nres <- residuals(poisson.mod.1, type = \"pearson\")\ns.res <- rstandard(poisson.mod.1, type = \"pearson\")\nlin.pred <- poisson.mod.1$linear.predictors\n\ndf1 <- data.frame(df, pred, res, s.res, lin.pred)\n\n#Standardized Pearson residual vs math plot\n\ndf1 %>%\n ggplot(aes(x = df1$math , y = df1$s.res)) +\n geom_point() +\n geom_hline(yintercept=c(3, 2, 0, -2, -3), color = \"red\", linetype = \"dashed\")+\n geom_smooth(se = FALSE)+\n ggtitle(\"Standardized residuals vs. Math\") +\n xlab(\"Math\") +\n ylab(\"Standardized Pearson residuals\")\n\n#Standardized Pearson residual vs fitted values\n\ndf1 %>%\n ggplot(aes(x = df1$pred , y = df1$s.res)) +\n geom_point() +\n geom_hline(yintercept=c(3, 2, 0, -2, -3), color = \"red\", linetype = \"dashed\")+\n geom_smooth(se = FALSE)+\n ggtitle(\"Standardized residuals vs. Math\") +\n xlab(\"Fitted values\") +\n ylab(\"Standardized Pearson residuals\")\n\n#Standardized Pearson residual vs linear predictor\n\ndf1 %>%\n ggplot(aes(x = df1$lin.pred , y = df1$s.res)) +\n geom_point() +\n geom_hline(yintercept=c(3, 2, 0, -2, -3), color = \"red\", linetype = \"dashed\")+\n geom_smooth(se = FALSE)+\n ggtitle(\"Standardized residuals vs. Math\") +\n xlab(\"Linear predictor\") +\n ylab(\"Standardized Pearson residuals\")\n```\n\nWe have four assumptions general assumptions for Poisson regression\n\n- 1. IID data.\n- 2. The distribution of the response is the one specified by the model, which here is Poisson.\n- 3. The mean of the distribution is linked to the explanatory variables by the `link function` that we specify. In Poisson is is log().\n\n- 4. The link relates to the explanatory variables in a `linear fashion`. Here linearity means using a linear combination of the regression parameters.\n  - For `iid data`, we must discuss how the data is generated and look for possible clustering. \n    - Here there could be some clustering among the students who are in the same program or same classroom, or same cohort, which would violate independence.\n\n  - The plot of the standardized residuals against `math` shows roughly the same variance throughout the math score range. \n    - There is no severe curvature in the plot, suggesting we don’t need a transformation or additional polynomial terms.\n\n    - Similarly, the plots of `residuals against the fitted values` and `linear predictor` have roughly constant variance. \n      - They show no evident curvature, so we can conclude that the link function fits well here.\n\n- We can also use these plots to check for `extreme residuals`. In this case, there are numerous residuals whose magnitudes are larger than 2 or 3, scattered across the range of math scores. \n\n- This may be a sign of `overdispersion`, meaning more variability in the\ncounts than the model estimated. \n\n- This is an indication that there may be important explanatory variables missing from the model\n\n\n\n\\newpage\n\n# Goodness of Fit\n\n$$H_0: \\text{Our Model is correct}$$\n- The Pearson Statistic $\\chi^2$ and Residual Deviance $D$ are often used to test the goodness of fit, where the null hypothesis is that our model is correct. Under asymptotic theory, both of these follow a chi-squared distribution with the same degrees of freedom as the residuals from the Poisson model.\n\nWe can also use these to test for overdispersion in our model since if our model is a good fit to the data we should not have overdispersion.\n\n## The Pearson Statistics\n\n\n$$\\chi^2=\\sum_{i=1}^{n}\\frac{(y_{i}-\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\})^{2}}{\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\}}$$\n\n```{r}\n#| echo: true\n# Calculate Pearson statistic residuals\npearson_stat <- sum(residuals(poisson.mod.1, type = \"pearson\")^2)\npearson_stat\n\n# Get p value associated with the pearson statistic\npearson_p.value <- pchisq(pearson_stat, poisson.mod.1$df.residual,\nlower.tail = FALSE)\npearson_p.value\n```\n\n\n## Residual Deviance \n\n$$D=2\\sum_{i=1}^{n}\\biggl[y_{i}\\log\\biggl(\\frac{y_{i}}{\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\}}\\biggr)-(y_{i}-\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\})\\biggr]$$\n\n\n```{r}\n#Calculate deviance p value\ndeviance_p.value <- pchisq(poisson.mod.1$deviance, poisson.mod.1$df.residual,\nlower.tail = FALSE)\ndeviance_p.value\n```\n\n- `Goodness-of-fit statistics` test is a more objective measure of the overall fit.\n\n- The null hypothesis is that the model is correct against the alternative that it is not.\n- We can use both Pearson statistic or the residual deviance to perform this test\n\n- Here, the two non significant p-values indicate that we `fail to reject the null hypothesis that the model is correct`\n\n\n\\newpage\n\n# Directly Testing for Over Dispersion\n\nWe can use a dispersion test for Poisson regression from the AER package that tests the null hypothesis that \n\n$$\\theta=1$$ \n\nvs. not in a regression of the form \n\n$$\\text{V}(Y_i)=(1+\\alpha)*\\lambda_i$$\n\n- Note that if we set $(1+\\alpha)=\\theta$ we get the variance form for a quasipoisson above. \n\n- So this test is examining whether the variance of our outcome variable appears to come from a Poisson or quasipoisson distribution.\n\nIf we reject the null hypothesis due to a small p-value, we have overdispersion if $\\alpha>0$ and underdispersion (smaller variance in reality which is less common) if $\\alpha<0$.\n\nThe test itself reports the estimated dispersion value along with a p-value.\n\nRun the test using `dispersiontest()`:\n\n```{r}\n#| echo: true\n# replace with your code\ndispersiontest(poisson.mod.1)\n```\n\n- Note the dispersion estimate above 1 but lack of significant `p-value` since it is larger than 0.05. \n  - This means we fail to reject the $H_0$ that poission regression is value.\n\n- If we reject the $H_0$ in an overdispersion test, that means we should fit a quasipoisson or `negative binomial regression`.\n\n- We can fit quasipoisson directly using `glm()` and specifying the appropriate family. \n- For a negative binomial using regression, we need to use `glm.nb()` from the MASS package.\n\n```{r}\n# quasipoisson regression\nquasi.poisson <- glm(num_awards ~ prog + math, data = df, family = quasipoisson)\n\n# negative binomial regression\nneg.binom <- glm.nb(num_awards ~ prog + math, data = df)\n```\n\n```{r}\nstargazer(poisson.mod.1, quasi.poisson, neg.binom, type=\"text\")\n```\n\n\n\\newpage\n\n## Reminders\n\n1. Before next live session: \n    1. Complete and turn in the Lab-1\n    2. Complete all videos and reading for unit 6\n\n","srcMarkdownNoYaml":"\n\n\n\n```{=html}\n<style>\n.table-hover > tbody > tr:hover { \n  background-color: #f4f442;\n}\n</style>\n```\n\n```{r message=FALSE, warning=FALSE, include=FALSE}\nlibrary(here)\nsource(here(\"source\",\"get_lib.R\"))\n```\n\n\nReading\n- Ch 4.1,4.2.1 - 4.2.3,5.2\n- Skim sections 5.1, 5.2.3,5.3,.5.4\n  \n# Generalized linear models (GLM)\n\n- GLMs have three different parts (see page 121:\n  \n  1. Random Component:\n      - $Y$, for logistic regression, $Y$ has a Bernoulli distribution\n  \n  2. Systematic Component:\n      - This specifies a linear combination of the regression parameters with `features`, and this part is referred to as the `linear predictor`\n      - $\\beta_0 + \\beta_1x_1 + .... + \\beta_px_p$\n      \n  3. LINK FUNCTION:\n      - Specifies how the expected value of the `random component` $E[Y]$ is linked to the `sysmatic` component.\n      - $\\text{logit}(\\pi) = \\beta_0 + \\beta_1x_1 + .... + \\beta_px_p$\n      - where $E[Y] = \\pi$\n\n\n## Class Announcements\n\nNo HW this week\n\nLab-1 due in 1 week\n\n## Roadmap\n\n**Rearview Mirror**\n\n- Model unordered and ordered categorical response \n\n**Today**\n\n- Poisson probability model\n\n- Poisson regression model, estimation, and statistical inference\n\n- Model Comparison Criteria, Model Assessment, Goodness of Fit\n\n**Looking Ahead**\n\n- Univariate and multivariate time-series\n\n- Notion of dependency and stationarity\n\n# Poisson Distribution \n\nRecall that the Poisson distribution models count data i.e. the number of events between 0,1,... for a random variable $X$. The distribution is:\n\n$$P(X=k)=\\frac{\\lambda^ke^{-\\lambda}}{k!}$$\nOne key assumption of the distribution is that $E(X)=Var(X)=\\lambda$, meaning that the mean and variance of the distribution is the same.\n\nAs we will see this is a limiting assumption when we do Poisson Regression.\n\n\nIn Poisson regression we model the log of $\\lambda$ (the mean assuming a Poisson distribution) as a linear combination of the features:\n\n$$\\text{log}(\\lambda_i)=\\text{log}(E(Y_i|X_i))=X_i\\beta$$\n\nWe use maximum likelihood to estimate the coefficients in $\\beta$ assuming that $Y$ follows an iid Poisson distribution:\n\n$$max_\\beta\\ L(\\beta|Y_1,...,Y_n)=P(Y_1=y_1,...,Y_n=y_n|\\beta)=\\Pi_i\\frac{e^{y_iX_i\\beta}e^{-e^{X_i\\beta}}}{y_i!}$$\n\nThe log likelihood has no closed form solution, so we estimate the parameters beta using numerical methods just like in logistic regression.\n\nFor each $y_i$ we can calculate and predict fitted values using the MLE of the coefficients:\n\n$$\\hat{y_i}=E(y_i|X_i)=\\lambda_i=e^{X_i\\beta}$$\nUnder Poisson regression, the $\\text{V}[\\hat{y_i}]=\\lambda_i=e^{X_i\\beta}$ so that Poisson regression naturally has heteroskedasticity in the results.\n\nBecause coefficients are linear on the log scale, when exponentiated they multiply the expected mean outcome. This is similar to the interpretation in logistic regression except we are not dealing with odds ratios but rather changes in the average outcome.\n\n## Parameter\n\nEqual Mean and Variance and Overdispersion\n\nThis assumption of equal mean and variance is often not met when actually fitting to data, which results in what is known as overdispersion where the variance in the data is larger than the variance fit in the model.\n\nThis usually can be remedied by adding more $X$ variables into the model to improve the fit.\n\nAnother option is to fit what are known as a quasi poisson model or negative binomial regression model. In both cases, we relax the equal mean and variance assumption by adding an additional parameter to the variance of the response variable, allowing it to be larger than the mean.\n\nIn quasi poisson regression we set $\n\n$$\\text{V}[\\hat{y_i}]=\\theta\\lambda_i$$ \nand in negative binomial regression we set \n\n$$\\text{V}[\\hat{y_i}]=\\lambda_i+\\kappa\\lambda_i^2$$\n\n\n# Case Study: Modeling the Number of Awards \n\n## Target\n\n  - `The number of awards` earned by students based on the `type of programs students were enrolled` in using historical admission data. \n  - `num_awards`: the number of awards earned by students at a high school in a year\n  - `math`: students’ scores on their final math exam\n  - `prog`: the type of program in which the students were enrolled \n    - `1 = General`\n    - `2 = Academic` \n    - `3 = Vocational`\n\n## EDA\n\n- What is the number of observations?\n- What is the number of variables? \n- Are there any redundant variables?\n- Are there any missing information?\n- Are there any duplicated records?\n- Are there any values in each of the variables that seem unreasonable?\n\n```{r}\ndf <- read.csv(\"./data/PossionEx1.csv\", \n               stringsAsFactors = F, \n               header=TRUE, sep=\",\")\n\nhead(df) %>%\n  kable(\"html\", caption = \"Modeling the Number of Awards\") %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n#str(df)\n\n## convert prog to factor\ndf$prog = factor(df$prog)\n  \n\n# Checking the number of missing values for each of the variables\n# df[!complete.cases(df),]\nsapply(df, function(x) sum(is.na(x)))\n\n```\n\n\\newpage\n\n### Univariate Analysis\n\n- Use a frequency table and a bar plot to explore the distribution of the response variable(num_awards). What do you learn?\n\n```{r}\n#| echo: false\ndf %>%\n  count(num_awards) %>%\n  mutate(prop = round(prop.table(n),2)) %>%\n  kable(\"html\", caption = \"Modeling the Number of Awards\",\n        col.names = c('Number of awards', 'N', \"Proportion\")) %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n  \n\ndf %>%\n  ggplot(aes(x= num_awards, y = ..prop.., group = 1)) + \n  geom_bar(fill = 'DarkBlue', color = 'black') +\n  geom_text(stat='count', aes(label=..count..), vjust= -1) + \n  xlab(\"Number of awards\") +\n  ylab(\"Proportion\") +\n  ylim(0,1)\n\n```\n\n- The prog is the committee’s key explanatory variable of interest. It has three levels: academic, general, and vocational. Use a frequency table and a bar plot to examine its distribution. What do you discover? \n\n```{r}\n#| echo: false\n#| \ndf %>%\n  count(prog) %>%\n  mutate(prop = round(prop.table(n),2)) %>%\n  kable(\"html\", caption = \"Modeling the Number of Awards\",\n        col.names = c(' Type of program', 'N', \"Proportion\")) %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\ndf %>%\n  ggplot(aes(x= prog, y = ..prop.., group = 1)) + \n  geom_bar(fill = 'DarkBlue', color = 'black') +\n  geom_text(stat='count', aes(label=..count..), vjust=-1) + \n  xlab(\"Type of program\") +\n  ylab(\"Proportion\") +\n  ylim(0,1)\n```\n\n- Plot the distribution of math scores. What are the range and average math scores?\n\n```{r warning=FALSE, error=FALSE, message=FALSE}\n#| echo: false\n\ndf %>% \n  ggplot(aes(x = math)) +\n  geom_histogram(aes(y = ..density..), binwidth = 5 ,fill = \"DarkBlue\", color = \"black\") +\n  geom_vline(aes(xintercept = mean(math)), color = \"red\", linetype = \"dashed\") +\n  ggtitle(\"Distribution of students’ math scores\") + \n  theme(plot.title = element_text(lineheight=1, face=\"bold\")) +\n  xlab(\"Socre\") +\n  ylab(\"Density\")\n\n```\n\n### Bivariate Analysis\n\n- Examine the associations between the number of awards and program and math scores.\n\n- The graph below shows the distribution of the number of awards by program types. How are awards distributed among different programs?\n```{r}\n#| echo: false\ndf %>% \n  ggplot(aes(x = num_awards)) +\n  geom_bar(aes(color = prog, fill = prog),alpha=0.2, position = \"dodge\" ) +\n  ggtitle(\"Distribution of the Number of Awards by Program Types\") + \n  xlab(\"Award\") +\n  ylab(\"Count\")\n\n```\n\n- The graph below shows the distribution of the number of awards and students' math scores. Is there any clear relationship between them?\n\n```{r}\n#| echo: false\ndf %>%\n  ggplot(aes(num_awards, math)) +\n  geom_boxplot(aes(fill = factor(num_awards))) + \n  geom_jitter()+\n  coord_flip() +\n  ggtitle(\"Math Score by the Number of Awards\") + \n  theme(plot.title = element_text(lineheight=1, face=\"bold\")) +\n  xlab(\"Number of Awards\") +\n  ylab(\"Math Score\") \n```\n\n- Use summary_factorlist() function from the finalfit package to tabulate data. What do you learn from the EDA?\n\n```{r}\n#| echo: false\ndependent <- \"num_awards\"\nexplanatory <- c(\"prog\", \"math\")\ndf %>% \n  summary_factorlist(dependent, explanatory, add_dependent_label = TRUE) %>%\n  kable(\"html\", caption = \"Modeling the Number of Awards\") %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n\n# Model Development\n\n- Given the specification of a poisson regression model below,\n\n$$\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 prog + \\beta_2 math + u$$\n\n- Estimate and interpret the model results using `glm()` and the correct `family` parameter:\n\n## Coefficients\n\n```{r}\n#| echo: true\npoisson.mod.1 <- poisson.mod.1 <- glm(num_awards ~ prog + math, \n                                      data = df, \n                                      family = poisson)\n\nsummary(poisson.mod.1)\n```\n\n- The `negative coefficients` of the `general` and `vocational programs` indicate that the number of wards is lower in these two programs.\n\n- The positive coefficients of `math` score indicates that the number of awards is increasing as the math score increases.\n\n```{r}\n#| echo: true\n\n(exp(coef(poisson.mod.1)) - 1) * 100\n```\n\nTo have a more convenient way to interpret these coefficients, we compute and use percentage changes\n  - Holding `program type constant`, 1 unit increase in math score increase the mean number of awards by 7%.\n\n  - Hold `math score constant`; \n    - a student in the `general program`, on average, receives 66% fewer awards than students in the `academic program`\n    - a student in the `vocational program`, on average, receives 51% fewer awards than students in the academic program\n\n### Anova()\n\n- Test the overall effect of prog using `Anova()`:   \n\n```{r}\n## test model differences with chi square test\nAnova(poisson.mod.1)\n```\n\n- Based on the p-values, the prog, taken together, is a statistically significant predictor of the number of awards.\n\n\n## Plot the result \n\n- Plot the fitted values across the three programs and discuss how the number of awards is associated with math scores.\n\n```{r}\n# uncomment and run the code\n\n## calculate and store predicted values\nfitted_values <- predict(poisson.mod.1, type=\"response\")\n\n## create the plot\n\np <- ggplot(df, aes(x = math, y = fitted_values, colour = prog)) +\n geom_point(aes(y = num_awards), alpha=.5, position=position_jitter(h=.2)) +\n geom_line(size = 1) +\n labs(x = \"Math Score\", y = \"Expected number of awards\")\n\nggplotly(p)\n```\n\n- This graph indicates that the most awards are earned by students in the `academic` program, especially if the student has a high math score. \n\n- Students in the `general program` earn the lowest number of awards\n\n## CI of cofficients\n\n- Construct and interpret the confidence intervals for each variable using `confint()`.\n    \n```{r}\n# Confident intervals for the original coefficient estimates\nbeta.interval <- confint(poisson.mod.1, level = 0.95)\n\nbeta.interval %>% kable(\"html\", caption = \"beta interval\") %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n# Convert the confidence intervals to percentage change, corresponding to the coefficient estimates\n\nas.data.frame(100 * (exp(beta.interval) - 1)) %>% \n  kable(\"html\", caption = \"beta interval\") %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n```\n\n- at $\\alpha = 0.05$, Compared to the students in `academic program`, the mean number of awards that students in `General program` decreases by 35% to 84% holding the math score constant.\n\n- With 95% confidence, the mean number of awards decrease by 11% to 75% for the student in `vocational program` vs. student in `academic programs`, holding the math score constant.\n\n-  95% confidence interval of a the effect of 1-unit increase in math score on the mean number of award holding everything else constant is `5.07% to 9.53% increase` \n\n\n\\newpage\n\n# Model Comparison Criteria\n\n[LINK1](https://stats.stackexchange.com/questions/232465/how-to-compare-models-on-the-basis-of-aic)\n[LINK2](https://www.scribbr.com/statistics/akaike-information-criterion/)\n\nRecall that the general form of most information criteria is:\n\n$$\\text{IC}(k)=-2log(L(\\hat{\\beta}|y_1,.....,y_n))+kr$$\n\nWhere \n\n- $\\text{log}(L(\\hat{\\beta}|y_1,.....,y_n))$ is the log-likelihood of an estimated model, - `n` is the sample size, \n- `r` is the number of parameters in the model, \n- `k` is a penalty term on the number of parameters. \n\nThe three most common information criteria are:\n\n## AIC\n\n$$AIC = IC(2) = -2log(L(\\hat{\\beta}|y_1,.....,y_n))+2r$$\n\n## AIC_c\n\n$$AIC_c = IC(\\frac{2n}{n-r-1}) = -2log(L(\\hat{\\beta}|y_1,.....,y_n))+r\\frac{2n}{n-r-1}=AIC+\\frac{2r(r+1)}{n-r-1}$$\n\n## BIC\n\n$$BIC = IC(log(n)) = -2log(L(\\hat{\\beta}|y_1,.....,y_n))+rlog(n)$$\n\n## Example\n\n- Compute these three information criteria for the following three models and then rank the models based on each criterion using `AIC()`, `BIC()`, and `AICc()`.  \n\n$$\\text{mod.1:   }\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 prog + u  $$\n$$\\text{mod.2:   }\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 math + u$$\n\n$$\\text{mod.3:   }\\log(mean\\_num\\_awards) = \\beta_0 + \\beta_1 prog + \\beta_2 math + u$$\n\n```{r}\n## fit models\nmod.1 <- glm(num_awards ~ math, data = df, family = poisson)\nmod.2 <- glm(num_awards ~ prog, data = df, family = poisson)\nmod.3 <- glm(num_awards ~ prog + math, data = df, family = poisson)\n\n## compute AIC\ndata.frame(mod.1 = AIC(mod.1, k = 2), mod.2 = AIC(mod.2), mod.3 = AIC(mod.3))\n\n## compute corrected AIC \ndata.frame(mod.1 = AICc(mod.1), mod.2 = AICc(mod.2), mod.3 = AICc(mod.3))\n\n## compute BIC\ndata.frame(mod.1 = BIC(mod.1), mod.2 = BIC(mod.2), mod.3 = BIC(mod.3))\n```\n\n- The model with the `lowest` AIC, corrected AIC, or BIC score is preferred. \n  - The absolute values of these scores do not matter.\n\n- These scores can be negative or positive.\n  - Based on all these three criteria, the third model with both math and program is the best, and the second model with the only program is the worst model\n\n\n# Model Assessment\n\nRecall that the Pearson residuals correct for unequal variance in the raw residuals by dividing by the standard deviation:\n\n$$e_m = \\frac{y_m - \\widehat{y_m}}{\\sqrt{\\widehat{\\text{V}(Y_m)}}}$$\n\nStandardized Pearson residuals also correct for overestimates of the standard deviation of $y_m - \\widehat{y_m}$:\n\n$$r_m = \\frac{y_m - \\widehat{y_m}}{\\sqrt{\\widehat{\\text{V}(Y_m-\\hat{Y_m})}}}=\\frac{y_m - \\widehat{y_m}}{\\sqrt{\\widehat{\\text{V}(Y_m)}-(1-h_m)}}$$\nwhere $h_m$ is the mth diagonal element of the hat matrix.\n\n- For the first Poisson model using `prog` and `math` as predictors, plot the standardized Pearson residuals against explanatory variables, fitted values, and the linear predictor to assess whether the model assumptions are satisfied. \n\n```{r message=FALSE, warning=FALSE}\n#| echo: false\npred <- predict(poisson.mod.1, type = \"response\")\nres <- residuals(poisson.mod.1, type = \"pearson\")\ns.res <- rstandard(poisson.mod.1, type = \"pearson\")\nlin.pred <- poisson.mod.1$linear.predictors\n\ndf1 <- data.frame(df, pred, res, s.res, lin.pred)\n\n#Standardized Pearson residual vs math plot\n\ndf1 %>%\n ggplot(aes(x = df1$math , y = df1$s.res)) +\n geom_point() +\n geom_hline(yintercept=c(3, 2, 0, -2, -3), color = \"red\", linetype = \"dashed\")+\n geom_smooth(se = FALSE)+\n ggtitle(\"Standardized residuals vs. Math\") +\n xlab(\"Math\") +\n ylab(\"Standardized Pearson residuals\")\n\n#Standardized Pearson residual vs fitted values\n\ndf1 %>%\n ggplot(aes(x = df1$pred , y = df1$s.res)) +\n geom_point() +\n geom_hline(yintercept=c(3, 2, 0, -2, -3), color = \"red\", linetype = \"dashed\")+\n geom_smooth(se = FALSE)+\n ggtitle(\"Standardized residuals vs. Math\") +\n xlab(\"Fitted values\") +\n ylab(\"Standardized Pearson residuals\")\n\n#Standardized Pearson residual vs linear predictor\n\ndf1 %>%\n ggplot(aes(x = df1$lin.pred , y = df1$s.res)) +\n geom_point() +\n geom_hline(yintercept=c(3, 2, 0, -2, -3), color = \"red\", linetype = \"dashed\")+\n geom_smooth(se = FALSE)+\n ggtitle(\"Standardized residuals vs. Math\") +\n xlab(\"Linear predictor\") +\n ylab(\"Standardized Pearson residuals\")\n```\n\nWe have four assumptions general assumptions for Poisson regression\n\n- 1. IID data.\n- 2. The distribution of the response is the one specified by the model, which here is Poisson.\n- 3. The mean of the distribution is linked to the explanatory variables by the `link function` that we specify. In Poisson is is log().\n\n- 4. The link relates to the explanatory variables in a `linear fashion`. Here linearity means using a linear combination of the regression parameters.\n  - For `iid data`, we must discuss how the data is generated and look for possible clustering. \n    - Here there could be some clustering among the students who are in the same program or same classroom, or same cohort, which would violate independence.\n\n  - The plot of the standardized residuals against `math` shows roughly the same variance throughout the math score range. \n    - There is no severe curvature in the plot, suggesting we don’t need a transformation or additional polynomial terms.\n\n    - Similarly, the plots of `residuals against the fitted values` and `linear predictor` have roughly constant variance. \n      - They show no evident curvature, so we can conclude that the link function fits well here.\n\n- We can also use these plots to check for `extreme residuals`. In this case, there are numerous residuals whose magnitudes are larger than 2 or 3, scattered across the range of math scores. \n\n- This may be a sign of `overdispersion`, meaning more variability in the\ncounts than the model estimated. \n\n- This is an indication that there may be important explanatory variables missing from the model\n\n\n\n\\newpage\n\n# Goodness of Fit\n\n$$H_0: \\text{Our Model is correct}$$\n- The Pearson Statistic $\\chi^2$ and Residual Deviance $D$ are often used to test the goodness of fit, where the null hypothesis is that our model is correct. Under asymptotic theory, both of these follow a chi-squared distribution with the same degrees of freedom as the residuals from the Poisson model.\n\nWe can also use these to test for overdispersion in our model since if our model is a good fit to the data we should not have overdispersion.\n\n## The Pearson Statistics\n\n\n$$\\chi^2=\\sum_{i=1}^{n}\\frac{(y_{i}-\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\})^{2}}{\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\}}$$\n\n```{r}\n#| echo: true\n# Calculate Pearson statistic residuals\npearson_stat <- sum(residuals(poisson.mod.1, type = \"pearson\")^2)\npearson_stat\n\n# Get p value associated with the pearson statistic\npearson_p.value <- pchisq(pearson_stat, poisson.mod.1$df.residual,\nlower.tail = FALSE)\npearson_p.value\n```\n\n\n## Residual Deviance \n\n$$D=2\\sum_{i=1}^{n}\\biggl[y_{i}\\log\\biggl(\\frac{y_{i}}{\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\}}\\biggr)-(y_{i}-\\exp\\{\\textbf{X}_{i}\\hat{\\beta}\\})\\biggr]$$\n\n\n```{r}\n#Calculate deviance p value\ndeviance_p.value <- pchisq(poisson.mod.1$deviance, poisson.mod.1$df.residual,\nlower.tail = FALSE)\ndeviance_p.value\n```\n\n- `Goodness-of-fit statistics` test is a more objective measure of the overall fit.\n\n- The null hypothesis is that the model is correct against the alternative that it is not.\n- We can use both Pearson statistic or the residual deviance to perform this test\n\n- Here, the two non significant p-values indicate that we `fail to reject the null hypothesis that the model is correct`\n\n\n\\newpage\n\n# Directly Testing for Over Dispersion\n\nWe can use a dispersion test for Poisson regression from the AER package that tests the null hypothesis that \n\n$$\\theta=1$$ \n\nvs. not in a regression of the form \n\n$$\\text{V}(Y_i)=(1+\\alpha)*\\lambda_i$$\n\n- Note that if we set $(1+\\alpha)=\\theta$ we get the variance form for a quasipoisson above. \n\n- So this test is examining whether the variance of our outcome variable appears to come from a Poisson or quasipoisson distribution.\n\nIf we reject the null hypothesis due to a small p-value, we have overdispersion if $\\alpha>0$ and underdispersion (smaller variance in reality which is less common) if $\\alpha<0$.\n\nThe test itself reports the estimated dispersion value along with a p-value.\n\nRun the test using `dispersiontest()`:\n\n```{r}\n#| echo: true\n# replace with your code\ndispersiontest(poisson.mod.1)\n```\n\n- Note the dispersion estimate above 1 but lack of significant `p-value` since it is larger than 0.05. \n  - This means we fail to reject the $H_0$ that poission regression is value.\n\n- If we reject the $H_0$ in an overdispersion test, that means we should fit a quasipoisson or `negative binomial regression`.\n\n- We can fit quasipoisson directly using `glm()` and specifying the appropriate family. \n- For a negative binomial using regression, we need to use `glm.nb()` from the MASS package.\n\n```{r}\n# quasipoisson regression\nquasi.poisson <- glm(num_awards ~ prog + math, data = df, family = quasipoisson)\n\n# negative binomial regression\nneg.binom <- glm.nb(num_awards ~ prog + math, data = df)\n```\n\n```{r}\nstargazer(poisson.mod.1, quasi.poisson, neg.binom, type=\"text\")\n```\n\n\n\\newpage\n\n## Reminders\n\n1. Before next live session: \n    1. Complete and turn in the Lab-1\n    2. Complete all videos and reading for unit 6\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"html-math-method":"katex","css":["style.css"],"output-file":"wk5.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","title":"Possion regression","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}