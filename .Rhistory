save.true.conf <- matrix(data = NA, nrow = length(pi.seq), ncol = 5)
# Create counter for the loop
counter <- 1
# Loop over each pi that the true confidence level is calculated on
for(pi in pi.seq) {
pmf <- dbinom(x = w, size = n, prob = pi)
# Wald
save.wald <- pi>lower.wald & pi<upper.wald  # Check if pi is within interval
# Could use ifelse() too:
# save.wald <- ifelse(test = pi>lower.wald, yes = ifelse(test = pi<upper.wald, yes = 1, no = 0), no = 0)
wald <- sum(save.wald*pmf)
# Agresti-Coull
save.AC <- pi>lower.AC & pi<upper.AC
# ifelse(test = pi>lower.AC, yes = ifelse(test = pi<upper.AC, yes = 1, no = 0), no = 0)
AC <- sum(save.AC*pmf)
# Wilson
save.wilson <- pi>lower.wilson & pi<upper.wilson
# save.wilson <- ifelse(test = pi>lower.wilson, yes = ifelse(test = pi<upper.wilson, yes = 1, no = 0), no = 0)
wilson <- sum(save.wilson*pmf)
# Clopper-Pearson
save.CP <- pi>lower.CP & pi<upper.CP
# save.CP <- ifelse(test = pi>lower.CP, yes = ifelse(test = pi<upper.CP, yes = 1, no = 0), no = 0)
CP <- sum(save.CP*pmf)
save.true.conf[counter,] <- c(pi, wald, AC, wilson, CP)
counter <- counter+1
}
plot(x = save.true.conf[,1], y = save.true.conf[,2], main = "Wald", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
# Plots
# dev.new(width = 7, height = 6, pointsize = 12)
# pdf(file = "c:\\figures\\Figure1.3.pdf", width = 7, height = 6, colormodel = "cmyk")   # Create plot for book
par(mfrow = c(2,2))  # 2x2 plotting grid
plot(x = save.true.conf[,1], y = save.true.conf[,2], main = "Wald", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
segments(x0 = 0.157, y0 = 0, x1 = 0.157,
y1 = save.true.conf[save.true.conf[,1]==0.157,2], lty = "dotdash")
segments(x0 = -1, y0 = save.true.conf[save.true.conf[,1]==0.157,2], x1 = 0.157,
y1 = save.true.conf[save.true.conf[,1]==0.157,2], lty = "dotdash")
plot(x = save.true.conf[,1], y = save.true.conf[,3], main = "Agresti-Coull", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
plot(x = save.true.conf[,1], y = save.true.conf[,4], main = "Wilson", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
plot(x = save.true.conf[,1], y = save.true.conf[,5], main = "Clopper-Pearson", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
# Pi = 0.157
save.true.conf[save.true.conf[,1]==0.157, ]
# Pi = 0.157
# save.true.conf[save.true.conf[,1]==0.157, ]
# While AC and Wilson have same true confidence levels at pi=0.157, this will not always be the case
sum(save.true.conf[,3] != save.true.conf[,4])  # Number of differences
# Initial settings and calculations
alpha <- 0.05
n <- 40
w <- 0:n
pi.hat <- w/n
pi.tilde <- (w + qnorm(p = 1-alpha/2)^2 /2) / (n+qnorm(1-alpha/2)^2)
# Wald
var.wald <- pi.hat*(1-pi.hat)/n
lower.wald <- pi.hat - qnorm(p = 1-alpha/2) * sqrt(var.wald)
upper.wald <- pi.hat + qnorm(p = 1-alpha/2) * sqrt(var.wald)
# Agresti-Coull
lower.AC <- pi.tilde - qnorm(p = 1-alpha/2) * sqrt(pi.tilde*(1-pi.tilde) / (n+qnorm(1-alpha/2)^2))
upper.AC <- pi.tilde + qnorm(p = 1-alpha/2) * sqrt(pi.tilde*(1-pi.tilde) / (n+qnorm(1-alpha/2)^2))
# Wilson
lower.wilson <- pi.tilde - qnorm(p = 1-alpha/2) * sqrt(n) / (n+qnorm(1-alpha/2)^2) * sqrt(pi.hat*(1-pi.hat) + qnorm(1-alpha/2)^2/(4*n))
upper.wilson <- pi.tilde + qnorm(p = 1-alpha/2) * sqrt(n) / (n+qnorm(1-alpha/2)^2) * sqrt(pi.hat*(1-pi.hat) + qnorm(1-alpha/2)^2/(4*n))
# Clopper-Pearson - This is a little more complicated due to the y = 0 and n cases
lower.CP <- numeric(n+1)  # This initializes a vector to save the lower bounds into
upper.CP <- numeric(n+1)  # This initializes a vector to save the upper bounds into
# y = 0
w0<-0  # Set here for emphasis
lower.CP[1] <- 0
upper.CP[1] <- qbeta(p = 1-alpha/2, shape1 = w0+1, shape2 = n-w0)
# y = n
wn <-n  # Set here for emphasis
lower.CP[n+1] <- qbeta(p = alpha/2, shape1 = wn, shape2 = n-wn+1)
upper.CP[n+1] <- 1
# y = 1, ..., n-1
w.new <- 1:(n-1)
lower.CP[2:n] <- qbeta(p = alpha/2, shape1 = w.new, shape2 = n-w.new+1)
upper.CP[2:n] <- qbeta(p = 1-alpha/2, shape1 = w.new+1, shape2 = n-w.new)
# All pi's
pi.seq <- seq(from = 0.001, to = 0.999, by = 0.0005)
# pi.seq<-0.16 #Testing
# pi.seq<-seq(from = 0.1, to = 0.9, by = 0.1) #Testing
# Save true confidence levels in a matrix
save.true.conf <- matrix(data = NA, nrow = length(pi.seq), ncol = 5)
# Create counter for the loop
counter <- 1
# Loop over each pi that the true confidence level is calculated on
for(pi in pi.seq) {
pmf <- dbinom(x = w, size = n, prob = pi)
# Wald
save.wald <- pi>lower.wald & pi<upper.wald  # Check if pi is within interval
# Could use ifelse() too:
# save.wald <- ifelse(test = pi>lower.wald, yes = ifelse(test = pi<upper.wald, yes = 1, no = 0), no = 0)
wald <- sum(save.wald*pmf)
# Agresti-Coull
save.AC <- pi>lower.AC & pi<upper.AC
# ifelse(test = pi>lower.AC, yes = ifelse(test = pi<upper.AC, yes = 1, no = 0), no = 0)
AC <- sum(save.AC*pmf)
# Wilson
save.wilson <- pi>lower.wilson & pi<upper.wilson
# save.wilson <- ifelse(test = pi>lower.wilson, yes = ifelse(test = pi<upper.wilson, yes = 1, no = 0), no = 0)
wilson <- sum(save.wilson*pmf)
# Clopper-Pearson
save.CP <- pi>lower.CP & pi<upper.CP
# save.CP <- ifelse(test = pi>lower.CP, yes = ifelse(test = pi<upper.CP, yes = 1, no = 0), no = 0)
CP <- sum(save.CP*pmf)
save.true.conf[counter,] <- c(pi, wald, AC, wilson, CP)
counter <- counter+1
}
# Plots
# dev.new(width = 7, height = 6, pointsize = 12)
# pdf(file = "c:\\figures\\Figure1.3.pdf", width = 7, height = 6, colormodel = "cmyk")   # Create plot for book
par(mfrow = c(2,2))  # 2x2 plotting grid
plot(x = save.true.conf[,1], y = save.true.conf[,2], main = "Wald", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
segments(x0 = 0.157, y0 = 0, x1 = 0.157,
y1 = save.true.conf[save.true.conf[,1]==0.157,2], lty = "dotdash")
segments(x0 = -1, y0 = save.true.conf[save.true.conf[,1]==0.157,2], x1 = 0.157,
y1 = save.true.conf[save.true.conf[,1]==0.157,2], lty = "dotdash")
plot(x = save.true.conf[,1], y = save.true.conf[,3], main = "Agresti-Coull", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
plot(x = save.true.conf[,1], y = save.true.conf[,4], main = "Wilson", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
plot(x = save.true.conf[,1], y = save.true.conf[,5], main = "Clopper-Pearson", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
# dev.off()  # Create plot for book
# Pi = 0.157
# save.true.conf[save.true.conf[,1]==0.157, ]
# While AC and Wilson have same true confidence levels at pi=0.157, this will not always be the case
# sum(save.true.conf[,3] != save.true.conf[,4])  # Number of differences
# length(pi.seq)  # Number of true confidence levels
prop.test(x = c.table , conf.level = 0.95, correct = FALSE)
c.table <- array(data = c(57, 142, 200688, 201087), dim =
c(2,2), dimnames = list(Treatment = c("vaccine", "placebo"), Result = c("polio", "polio free")))
c.table
pi.hat.table <- c.table/rowSums(c.table) > pi.hat.table
pi.hat.table
pi.hat.table <- c.table/rowSums(c.table)
pi.hat.table
sum(pi.hat.table)
pi.hat.table
sum(pi.hat.table)
var.log.rr <- (1-pi.hat1)/(n1*pi.hat1) +
(1-pi.hat2)/(n2*pi.hat2)
ci <- exp(log(pi.hat1/pi.hat2) + qnorm(p = c(alpha/2,
1-alpha/2)) * sqrt(var.log.rr))
var.log.rr <- (1-pi.hat1)/(n1*pi.hat1) + (1-pi.hat2)/(n2*pi.hat2)
n1 <- sum(c.table[1,])
n2 <- sum(c.table[2,])
var.log.rr <- (1-pi.hat1)/(n1*pi.hat1) + (1-pi.hat2)/(n2*pi.hat2)
ci <- exp(log(pi.hat1/pi.hat2) + qnorm(p = c(alpha/2,
1-alpha/2)) * sqrt(var.log.rr))
ci
#| echo: true
c.table <- array(data = c(57, 142, 200688, 201087), dim =
c(2,2), dimnames = list(Treatment = c("vaccine", "placebo"), Result = c("polio", "polio free")))
c.table
#calculate conditional probability
pi.hat.table <- c.table/rowSums(c.table)
pi.hat.table
#set type 1 error
alpha <- 0.05
n1 <- sum(c.table[1,])
n2 <- sum(c.table[2,])
var.log.rr <- (1-pi.hat1)/(n1*pi.hat1) + (1-pi.hat2)/(n2*pi.hat2)
ci <- exp(log(pi.hat1/pi.hat2) + qnorm(p = c(alpha/2,
1-alpha/2)) * sqrt(var.log.rr))
ci
c.table
#calculate conditional probability
pi.hat.table <- c.table/rowSums(c.table)
pi.hat.table
#estimated parameters to be compared
pi.hat1 <- pi.hat.table[1,1]
pi.hat2 <- pi.hat.table[2,1]
#set type 1 error
alpha <- 0.05
n1 <- sum(c.table[1,])
n2 <- sum(c.table[2,])
var.log.rr <- (1-pi.hat1)/(n1*pi.hat1) + (1-pi.hat2)/(n2*pi.hat2)
ci <- exp(log(pi.hat1/pi.hat2) + qnorm(p = c(alpha/2,
1-alpha/2)) * sqrt(var.log.rr))
ci
RR <- pi.hat1/pi.hat2
RR
# library(here)
# library(readxl)
df <- read_excel(here("def.xlsx"), sheet = "or")
#| label: tbl-penguins-top10
#| tbl-cap: First 10 Penguins
#replacing NA with white space
df[is.na(df)] <- ""
df %>% kable("html") %>%
kable_styling(bootstrap_options = c("striped", "hover"))
OR.hat <- c.table[1,1] * c.table[2,2] / (c.table[2,1] *
c.table[1,2])
round(OR.hat , 4)
#get confidence interval
alpha <- 0.05
var.log.or <- 1/c.table[1,1] + 1/c.table[1,2] + 1/c.table[2,1]
+ 1/c.table[2,2]
OR.CI <- exp(log(OR.hat) + qnorm(p = c(alpha/2, 1-alpha /2)) *
sqrt(var.log.or))
round(OR.CI , 2)
c.table <- array(data = c(4, 3, 6, 3), dim = c(2,2), dimnames =
list(MRI = c("Localized", "Advanced"), Ultrasound =
c("Localized", "Advanced"))) > c.table
c.table
c.table <- array(data = c(4, 3, 6, 3), dim = c(2,2), dimnames =
list(MRI = c("Localized", "Advanced"), Ultrasound =
c("Localized", "Advanced")))
c.table
n <- sum(c.table)
pi.hat.plus1 <- sum(c.table[,1])/n
pi.hat.plus1
pi.hat.1plus
pi.hat.1plus <- sum(c.table[1,])/n
pi.hat.1plus
data.frame(pi.hat.plus1 , pi.hat.1plus , diff = pi.hat.plus1 pi.hat.1plus)
data.frame(pi.hat.plus1 , pi.hat.1plus ,
diff = pi.hat.plus1 - pi.hat.1plus)
library(package = PropCIs)
diffpropci.Wald.mp(b = c.table[1,2], c = c.table[2,1], n =
sum(c.table), conf.level = 0.95)
#library(PropCIs)
diffpropci.Wald.mp(b = c.table[1,2], c = c.table[2,1], n =
sum(c.table), conf.level = 0.95)
diffpropci.mp(b = c.table[1,2], c = c.table[2,1], n =
sum(c.table), conf.level = 0.95)
mcnemar.test(x = c.table , correct = FALSE)
#get marginal distribution
n <- sum(c.table)
pi.hat.plus1 <- sum(c.table[,1])/n
pi.hat.1plus <- sum(c.table[1,])/n
#evaluate the difference by
#subtracting the sample statistics
data.frame(pi.hat.plus1 , pi.hat.1plus ,
diff = pi.hat.plus1 - pi.hat.1plus)
c.table <- array(data = c(4, 3, 6, 3), dim = c(2,2), dimnames =
list(MRI = c("Localized", "Advanced"), Ultrasound =
c("Localized", "Advanced")))
c.table
mcnemar.test(x = c.table , correct = FALSE)
#get marginal distribution
n <- sum(c.table)
pi.hat.plus1 <- sum(c.table[,1])/n
pi.hat.1plus <- sum(c.table[1,])/n
#evaluate the difference by
#subtracting the sample statistics
data.frame(pi.hat.plus1 , pi.hat.1plus ,
diff = pi.hat.plus1 - pi.hat.1plus)
##library(PropCIs)
## wald confidence interval
diffpropci.Wald.mp(b = c.table[1,2], c = c.table[2,1], n =
sum(c.table), conf.level = 0.95)
# Chunk 1
#| message: false
#| warning: false
#| include: false
library(here)
source(here("source","get_lib.R"))
# Chunk 2
loglikelihood <- function(pi) {
data <- c(1, 0, 1)
return(sum(data==1)*log(pi) + (sum(data==0)*log(1-pi)))}
# Chunk 3
prob = seq(0, 1, by=.001)
d1 <- data.frame(probability = prob, log_likelihood = loglikelihood(prob))
ggplot(d1, aes(x = probability, y = log_likelihood)) +
geom_line() +
geom_vline(aes(xintercept = c(2/3)), color = "red", linetype = "dashed")+
scale_x_continuous(breaks = seq(0, 1, by = 0.1)) +
labs(title = "Computed Log-Likelihood for Bernoulli Parameter",
x = quote(pi),
y = 'log likelihood'
)
# Chunk 4
# Initial settings and calculations
alpha <- 0.05
n <- 40
w <- 0:n
pi.hat <- w/n
pi.tilde <- (w + qnorm(p = 1-alpha/2)^2 /2) / (n+qnorm(1-alpha/2)^2)
# Wald
var.wald <- pi.hat*(1-pi.hat)/n
lower.wald <- pi.hat - qnorm(p = 1-alpha/2) * sqrt(var.wald)
upper.wald <- pi.hat + qnorm(p = 1-alpha/2) * sqrt(var.wald)
# Agresti-Coull
lower.AC <- pi.tilde - qnorm(p = 1-alpha/2) * sqrt(pi.tilde*(1-pi.tilde) / (n+qnorm(1-alpha/2)^2))
upper.AC <- pi.tilde + qnorm(p = 1-alpha/2) * sqrt(pi.tilde*(1-pi.tilde) / (n+qnorm(1-alpha/2)^2))
# Wilson
lower.wilson <- pi.tilde - qnorm(p = 1-alpha/2) * sqrt(n) / (n+qnorm(1-alpha/2)^2) * sqrt(pi.hat*(1-pi.hat) + qnorm(1-alpha/2)^2/(4*n))
upper.wilson <- pi.tilde + qnorm(p = 1-alpha/2) * sqrt(n) / (n+qnorm(1-alpha/2)^2) * sqrt(pi.hat*(1-pi.hat) + qnorm(1-alpha/2)^2/(4*n))
# Clopper-Pearson - This is a little more complicated due to the y = 0 and n cases
lower.CP <- numeric(n+1)  # This initializes a vector to save the lower bounds into
upper.CP <- numeric(n+1)  # This initializes a vector to save the upper bounds into
# y = 0
w0<-0  # Set here for emphasis
lower.CP[1] <- 0
upper.CP[1] <- qbeta(p = 1-alpha/2, shape1 = w0+1, shape2 = n-w0)
# y = n
wn <-n  # Set here for emphasis
lower.CP[n+1] <- qbeta(p = alpha/2, shape1 = wn, shape2 = n-wn+1)
upper.CP[n+1] <- 1
# y = 1, ..., n-1
w.new <- 1:(n-1)
lower.CP[2:n] <- qbeta(p = alpha/2, shape1 = w.new, shape2 = n-w.new+1)
upper.CP[2:n] <- qbeta(p = 1-alpha/2, shape1 = w.new+1, shape2 = n-w.new)
# All pi's
pi.seq <- seq(from = 0.001, to = 0.999, by = 0.0005)
# pi.seq<-0.16 #Testing
# pi.seq<-seq(from = 0.1, to = 0.9, by = 0.1) #Testing
# Save true confidence levels in a matrix
save.true.conf <- matrix(data = NA, nrow = length(pi.seq), ncol = 5)
# Create counter for the loop
counter <- 1
# Loop over each pi that the true confidence level is calculated on
for(pi in pi.seq) {
pmf <- dbinom(x = w, size = n, prob = pi)
# Wald
save.wald <- pi>lower.wald & pi<upper.wald  # Check if pi is within interval
# Could use ifelse() too:
# save.wald <- ifelse(test = pi>lower.wald, yes = ifelse(test = pi<upper.wald, yes = 1, no = 0), no = 0)
wald <- sum(save.wald*pmf)
# Agresti-Coull
save.AC <- pi>lower.AC & pi<upper.AC
# ifelse(test = pi>lower.AC, yes = ifelse(test = pi<upper.AC, yes = 1, no = 0), no = 0)
AC <- sum(save.AC*pmf)
# Wilson
save.wilson <- pi>lower.wilson & pi<upper.wilson
# save.wilson <- ifelse(test = pi>lower.wilson, yes = ifelse(test = pi<upper.wilson, yes = 1, no = 0), no = 0)
wilson <- sum(save.wilson*pmf)
# Clopper-Pearson
save.CP <- pi>lower.CP & pi<upper.CP
# save.CP <- ifelse(test = pi>lower.CP, yes = ifelse(test = pi<upper.CP, yes = 1, no = 0), no = 0)
CP <- sum(save.CP*pmf)
save.true.conf[counter,] <- c(pi, wald, AC, wilson, CP)
counter <- counter+1
}
# Plots
# dev.new(width = 7, height = 6, pointsize = 12)
# pdf(file = "c:\\figures\\Figure1.3.pdf", width = 7, height = 6, colormodel = "cmyk")   # Create plot for book
par(mfrow = c(2,2))  # 2x2 plotting grid
plot(x = save.true.conf[,1], y = save.true.conf[,2], main = "Wald", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
segments(x0 = 0.157, y0 = 0, x1 = 0.157,
y1 = save.true.conf[save.true.conf[,1]==0.157,2], lty = "dotdash")
segments(x0 = -1, y0 = save.true.conf[save.true.conf[,1]==0.157,2], x1 = 0.157,
y1 = save.true.conf[save.true.conf[,1]==0.157,2], lty = "dotdash")
plot(x = save.true.conf[,1], y = save.true.conf[,3], main = "Agresti-Coull", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
plot(x = save.true.conf[,1], y = save.true.conf[,4], main = "Wilson", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
plot(x = save.true.conf[,1], y = save.true.conf[,5], main = "Clopper-Pearson", xlab = expression(pi),
ylab = "True confidence level", type = "l", ylim = c(0.85,1))
abline(h = 1-alpha, lty = "dotted")
# dev.off()  # Create plot for book
# Pi = 0.157
# save.true.conf[save.true.conf[,1]==0.157, ]
# While AC and Wilson have same true confidence levels at pi=0.157, this will not always be the case
# sum(save.true.conf[,3] != save.true.conf[,4])  # Number of differences
# length(pi.seq)  # Number of true confidence levels
# Chunk 5
#| echo: true
c.table <- array(data = c(251, 48, 34, 5), dim = c(2,2),
dimnames = list(First = c("made", "missed"), Second = c("made", "missed")))
c.table
#conditional probabilities
pi.hat.table <- c.table/rowSums(c.table)
#get the pi estimates
pi.hat1 <- pi.hat.table[1,1]
pi.hat2 <- pi.hat.table[2,1]
#set type I error
alpha <- 0.05
# Chunk 6
#########################
#wald CI
#########################
var.wald <- pi.hat1*(1-pi.hat1) / sum(c.table[1,]) +
pi.hat2*(1-pi.hat2) / sum(c.table[2,])
pi.hat1 - pi.hat2 + qnorm(p = c(alpha/2, 1-alpha /2)) *
sqrt(var.wald)
# Chunk 7
#########################
# Agresti-Caffo
#########################
pi.tilde1 <- (c.table[1,1] + 1) / (sum(c.table[1,]) + 2)
pi.tilde2 <- (c.table[2,1] + 1) / (sum(c.table[2,]) + 2)
var.AC <- pi.tilde1*(1-pi.tilde1) / (sum(c.table[1,]) + 2) +
pi.tilde2*(1-pi.tilde2) / (sum(c.table[2,]) + 2)
pi.tilde1 - pi.tilde2 + qnorm(p = c(alpha/2, 1-alpha /2)) *sqrt(var.AC)
# Chunk 8
#| echo: true
prop.test(x = c.table , conf.level = 0.95, correct = FALSE)
# Chunk 9
#| echo: true
c.table <- array(data = c(57, 142, 200688, 201087), dim =
c(2,2), dimnames = list(Treatment = c("vaccine", "placebo"), Result = c("polio", "polio free")))
c.table
#calculate conditional probability
pi.hat.table <- c.table/rowSums(c.table)
pi.hat.table
#estimated parameters to be compared
pi.hat1 <- pi.hat.table[1,1]
pi.hat2 <- pi.hat.table[2,1]
RR <- pi.hat1/pi.hat2
RR
# Chunk 10
#| echo: true
#set type 1 error
alpha <- 0.05
n1 <- sum(c.table[1,])
n2 <- sum(c.table[2,])
var.log.rr <- (1-pi.hat1)/(n1*pi.hat1) + (1-pi.hat2)/(n2*pi.hat2)
ci <- exp(log(pi.hat1/pi.hat2) + qnorm(p = c(alpha/2,
1-alpha/2)) * sqrt(var.log.rr))
ci
# Chunk 11
# library(here)
# library(readxl)
df <- read_excel(here("def.xlsx"), sheet = "or")
# Chunk 12: tbl-penguins-top10
#| label: tbl-penguins-top10
#| tbl-cap: First 10 Penguins
#replacing NA with white space
df[is.na(df)] <- ""
df %>% kable("html") %>%
kable_styling(bootstrap_options = c("striped", "hover"))
# Chunk 13
OR.hat <- c.table[1,1] * c.table[2,2] / (c.table[2,1] *
c.table[1,2])
round(OR.hat , 4)
#get confidence interval
alpha <- 0.05
var.log.or <- 1/c.table[1,1] + 1/c.table[1,2] + 1/c.table[2,1]
+ 1/c.table[2,2]
OR.CI <- exp(log(OR.hat) + qnorm(p = c(alpha/2, 1-alpha /2)) *
sqrt(var.log.or))
round(OR.CI , 2)
# Chunk 14
#| echo: true
#get marginal distribution
n <- sum(c.table)
pi.hat.plus1 <- sum(c.table[,1])/n
pi.hat.1plus <- sum(c.table[1,])/n
#evaluate the difference by
#subtracting the sample statistics
data.frame(pi.hat.plus1 , pi.hat.1plus ,
diff = pi.hat.plus1 - pi.hat.1plus)
# Chunk 15
#| echo: true
c.table <- array(data = c(4, 3, 6, 3), dim = c(2,2), dimnames =
list(MRI = c("Localized", "Advanced"), Ultrasound =
c("Localized", "Advanced")))
c.table
mcnemar.test(x = c.table , correct = FALSE)
##library(PropCIs)
## wald confidence interval
diffpropci.Wald.mp(b = c.table[1,2], c = c.table[2,1], n =
sum(c.table), conf.level = 0.95)
diffpropci.mp(b = c.table[1,2], c = c.table[2,1], n =
sum(c.table), conf.level = 0.95)
diffpropci.mp(b = c.table[1,2], c = c.table[2,1], n =
sum(c.table), conf.level = 0.95)
diffpropci.mp(b = c.table[1,2], c = c.table[2,2], n =
sum(c.table), conf.level = 0.95)
diffpropci.mp(b = c.table[1,2], c = c.table[2,1], n =
sum(c.table), conf.level = 0.95)
diffpropci.mp(b = c.table[1,1], c = c.table[2,1], n =
sum(c.table), conf.level = 0.95)
diffpropci.mp(b = c.table[1,2], c = c.table[2,1], n =
sum(c.table), conf.level = 0.95)
c.table
library(here)
source(here("source","get_lib.R"))
placekick <- read.table(here("data","Placekick.csv"),header = True, sep = ",")
placekick <- read.table(here("data","Placekick.csv"),header = T, sep = ",")
placekick
placekick %>% head %>% kable("html") %>%
kable_styling(bootstrap_options = c("striped", "hover"))
placekick %>% head %>% kable("html") %>%
kable_styling(bootstrap_options = c("striped", "hover"))
#fit the model
mod.fit <- glm(formula = good ~ distance , family =
binomial(link = logit), data = placekick)
mod.fit
latex_equation <- extract_eq(mod.fit)
print(latex_equation)
#fit the model
mod.fit <- glm(formula = good ~ distance , family =
binomial(link = logit), data = placekick)
latex_equation <- extract_eq(mod.fit)
print(latex_equation)
mod.fit
tidy(mod.fit)
confint(mod.fit)
summary(mod.fit)
